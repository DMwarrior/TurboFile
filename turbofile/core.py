#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Web file transfer system - core module.
Provides a web UI over rsync-based transfers.
"""

from flask import request
import paramiko
import threading
import os
import json
import time
import subprocess
import re
import asyncio
import concurrent.futures
import random
from datetime import datetime
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor
import multiprocessing
import shutil
import shlex
import uuid
import signal
import select
import pty
from difflib import SequenceMatcher

from .extensions import socketio

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir))
CONFIG_FILE = os.path.join(BASE_DIR, 'data', 'config.json')

def load_config():
    """Load config from data/config.json; raise if missing or invalid."""
    if not os.path.exists(CONFIG_FILE):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        cfg = json.load(f)
    if not isinstance(cfg, dict):
        raise ValueError("é…ç½®æ–‡ä»¶æ ¼å¼æ— æ•ˆï¼Œé¡¶å±‚åº”ä¸ºå¯¹è±¡")
    return cfg

CONFIG = load_config()

secret_key = CONFIG.get('secret_key')
if not secret_key:
    raise RuntimeError("é…ç½®ç¼ºå°‘ secret_key")

TURBOFILE_HOST_IP = CONFIG.get('host_ip') or ''
if not TURBOFILE_HOST_IP:
    raise RuntimeError("é…ç½®ç¼ºå°‘ host_ip")

SERVERS = CONFIG.get('servers')
if not isinstance(SERVERS, dict) or not SERVERS:
    raise RuntimeError("é…ç½®ç¼ºå°‘ servers åˆ—è¡¨")

ADMIN_MODE_ENABLED = bool(CONFIG.get('admin_mode_enabled'))
ADMIN_CLIENT_IPS = set(CONFIG.get('admin_client_ips') or [])

def extract_client_ipv4_from_request(req) -> str:
    """
    Extract client IPv4 from the request, preferring proxy headers for consistency.
    Return an empty string if unavailable.
    """
    try:
        def _extract_ipv4(s: str):
            if not s:
                return None
            first = s.split(',')[0].strip()
            m = re.search(r'(\d{1,3}(?:\.\d{1,3}){3})', first)
            return m.group(1) if m else None

        candidates = [
            req.headers.get('X-Forwarded-For', ''),
            req.headers.get('X-Real-IP', ''),
            req.remote_addr
        ]
        for c in candidates:
            ip = _extract_ipv4(c)
            if ip:
                return ip
    except Exception:
        pass
    return ''

def is_admin_client_ip(ip: str) -> bool:
    try:
        return bool(ADMIN_MODE_ENABLED and ip and ip in ADMIN_CLIENT_IPS)
    except Exception:
        return False



@lru_cache(maxsize=1)
def get_current_host_ip():
    """Get the current host IP address."""
    try:
        import socket

        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return TURBOFILE_HOST_IP

def determine_transfer_mode(source_server, target_server):
    """
    Determine transfer mode; any server can be a source.

    Returns:
    - 'local_to_remote': from TurboFile host to remote
    - 'remote_to_remote': from remote to another remote
    - 'remote_to_local': from remote to TurboFile host
    """
    current_host = get_current_host_ip()


    local_aliases = ["localhost", "127.0.0.1", current_host, TURBOFILE_HOST_IP]

    is_source_local = source_server in local_aliases
    is_target_local = target_server in local_aliases

    if is_source_local and not is_target_local:
        return 'local_to_remote'
    elif not is_source_local and is_target_local:
        return 'remote_to_local'
    elif not is_source_local and not is_target_local:
        return 'remote_to_remote'
    else:

        return 'local_to_local'

def is_local_server(server_ip):
    """Return whether the server is the local TurboFile host."""
    current_host = get_current_host_ip()
    local_aliases = ["localhost", "127.0.0.1", current_host, TURBOFILE_HOST_IP]
    return server_ip in local_aliases


def load_client_paths():
    global client_paths_cache
    if client_paths_cache:
        return client_paths_cache
    try:
        if not os.path.exists(CLIENT_PATH_FILE):
            os.makedirs(os.path.dirname(CLIENT_PATH_FILE), exist_ok=True)
            client_paths_cache = {}
            return client_paths_cache
        with open(CLIENT_PATH_FILE, 'r', encoding='utf-8') as f:
            text = f.read().strip()
            client_paths_cache = json.loads(text) if text else {}
    except Exception:
        client_paths_cache = {}
    return client_paths_cache

def save_client_paths():
    os.makedirs(os.path.dirname(CLIENT_PATH_FILE), exist_ok=True)
    tmp = CLIENT_PATH_FILE + '.tmp'
    with open(tmp, 'w', encoding='utf-8') as f:
        json.dump(client_paths_cache, f, ensure_ascii=False, indent=2)
    os.replace(tmp, CLIENT_PATH_FILE)

def remember_path(client_ip: str, panel: str, server: str, path: str):
    if not client_ip or not panel or not server or not path:
        return
    with CLIENT_PATH_LOCK:
        load_client_paths()
        client_paths_cache.setdefault(client_ip, {})
        client_paths_cache[client_ip][panel] = {'server': server, 'path': path}
        save_client_paths()


ssh_connections = {}
active_transfers = {}
transfer_processes = {}
TRANSFER_PROCESS_LOCK = threading.Lock()

def register_transfer_process(transfer_id: str, proc_info: dict) -> None:
    """Register a transfer process/channel (supports multiple parallel children)."""
    if not transfer_id or not isinstance(proc_info, dict):
        return
    with TRANSFER_PROCESS_LOCK:
        bucket = transfer_processes.get(transfer_id)
        if bucket is None:
            transfer_processes[transfer_id] = [proc_info]
        elif isinstance(bucket, list):
            bucket.append(proc_info)
        elif isinstance(bucket, dict):
            transfer_processes[transfer_id] = [bucket, proc_info]
        else:
            transfer_processes[transfer_id] = [proc_info]

def get_transfer_processes_snapshot(transfer_id: str):
    """Get a snapshot of transfer processes/channels to avoid concurrent mutation."""
    with TRANSFER_PROCESS_LOCK:
        bucket = transfer_processes.get(transfer_id)
        if bucket is None:
            return []
        if isinstance(bucket, list):
            return list(bucket)
        if isinstance(bucket, dict):
            return [bucket]
        return []
CLIENT_ROOMS = {}
CLIENT_PATH_LOCK = threading.Lock()
CLIENT_PATH_FILE = os.path.join(BASE_DIR, 'data', 'client_paths.json')
client_paths_cache = {}


TRANSFER_WATCHDOG_INTERVAL = 60
STALE_TRANSFER_TIMEOUT = 12 * 3600


PARALLEL_TRANSFER_CONFIG = {
    'max_workers': 8,
    'enable_parallel': True,
    'instant_start': True,
    'enable_folder_parallel': False,
    'folder_parallel_threshold': 1000,
    'enable_batch_transfer': True,
    'batch_max_files': 200
}


PERFORMANCE_CONFIG = {
    'speed_update_interval': 1,
    'progress_update_interval': 0.3,
    'disable_progress_monitoring': True,
    'reduce_websocket_traffic': True,
    'optimize_rsync_params': True
}


def _load_transfer_bytes_config():
    config = {
        'enabled': True,
        'update_interval': 2.0
    }
    raw = CONFIG.get('transfer_bytes_config')
    if not isinstance(raw, dict):
        return config
    enabled = raw.get('enabled')
    if isinstance(enabled, bool):
        config['enabled'] = enabled
    elif isinstance(enabled, int):
        config['enabled'] = bool(enabled)
    update_interval = raw.get('update_interval')
    if update_interval is not None:
        try:
            update_interval = float(update_interval)
            if update_interval > 0:
                config['update_interval'] = update_interval
        except (TypeError, ValueError):
            pass
    return config

TRANSFER_BYTES_CONFIG = _load_transfer_bytes_config()





RSYNC_SSH_CMD = "ssh -o Compression=no -o Ciphers=aes128-ctr -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o MACs=umac-64@openssh.com -o ControlMaster=auto -o ControlPersist=300 -o ControlPath=/tmp/turbofile-ssh-%r@%h:%p"


UI_LOG_FILTER_CONFIG = {
    'enabled': True,
    'skip_patterns': [
        'ğŸš€ å¼€å§‹',
        'ğŸ”„ ä¼ è¾“æ¨¡å¼',
        'ğŸ”§ è°ƒè¯•',
        'ğŸ“ æ‰§è¡Œå‘½ä»¤',
        'ğŸ“ æ­£åœ¨åˆ†æ',
        'âš¡ å¿«é€Ÿæ¨¡å¼',
        'âš¡ å¯åŠ¨',
        'ğŸ“Š å¹¶è¡Œä»»åŠ¡',
        'âœ… å¹¶è¡Œä»»åŠ¡å®Œæˆ',
        'ğŸ‰ ç›®å½•å¹¶è¡Œ',
        'âš ï¸ ç›®å½•',
        'ğŸ“ å¯ç”¨ç›®å½•',
        'ğŸ” æ£€æµ‹åˆ°Windows',
        'âœ‚ï¸',
        'ğŸ“ æœ¬åœ°åˆ°æœ¬åœ°',
        'ğŸªŸ Windows',
        'ğŸ§ Linux',
        'âš¡ï¸ å¼€å§‹ä¼ è¾“',
        'æ­£åœ¨ä¼ è¾“',
        'âœ… æœ¬åœ°å‰ªåˆ‡å®Œæˆ',
        'âœ… æœ¬åœ°å¤åˆ¶å®Œæˆ',
        'âœ… åŒæœåŠ¡å™¨å‰ªåˆ‡å®Œæˆ',
        'âœ… åŒæœåŠ¡å™¨å¤åˆ¶å®Œæˆ',
    ]
}

def should_emit_to_ui(message):
    """Decide whether to show the log message in the UI."""
    if not UI_LOG_FILTER_CONFIG['enabled']:
        return True


    for pattern in UI_LOG_FILTER_CONFIG['skip_patterns']:
        if pattern in message:
            return False


    return True

def emit_transfer_log(transfer_id, message):
    """Send transfer logs to the UI (with filtering)."""
    if should_emit_to_ui(message):
        socketio.emit('transfer_log', {
            'transfer_id': transfer_id,
            'message': message
        })

TRANSFER_BYTES_STATE = {}
TRANSFER_BYTES_LOCK = threading.Lock()
RSYNC_PROGRESS_BYTES_RE = re.compile(r'^\s*([0-9][0-9,]*)\s+\d+%')

def init_transfer_bytes(transfer_id):
    if not transfer_id:
        return
    with TRANSFER_BYTES_LOCK:
        TRANSFER_BYTES_STATE[transfer_id] = {
            'parts': {},
            'completed_total': 0
        }

def cleanup_transfer_bytes(transfer_id):
    if not transfer_id:
        return
    with TRANSFER_BYTES_LOCK:
        TRANSFER_BYTES_STATE.pop(transfer_id, None)

def update_transfer_bytes_part(transfer_id, part_id, bytes_val):
    if not transfer_id or not part_id:
        return
    try:
        bytes_val = int(bytes_val)
    except Exception:
        return
    with TRANSFER_BYTES_LOCK:
        state = TRANSFER_BYTES_STATE.setdefault(transfer_id, {'parts': {}, 'completed_total': 0})
        current = state['parts'].get(part_id)
        if current is None or bytes_val > current:
            state['parts'][part_id] = bytes_val

def finalize_transfer_bytes_part(transfer_id, part_id, final_bytes=None):
    if not transfer_id or not part_id:
        return
    with TRANSFER_BYTES_LOCK:
        state = TRANSFER_BYTES_STATE.setdefault(transfer_id, {'parts': {}, 'completed_total': 0})
        part_val = None
        if part_id in state['parts']:
            part_val = state['parts'].pop(part_id)
        if final_bytes is not None:
            try:
                final_bytes = int(final_bytes)
                if part_val is None or final_bytes > part_val:
                    part_val = final_bytes
            except Exception:
                pass
        if part_val is not None:
            state['completed_total'] += part_val

def get_transfer_bytes_total(transfer_id):
    if not transfer_id:
        return 0
    with TRANSFER_BYTES_LOCK:
        state = TRANSFER_BYTES_STATE.get(transfer_id)
        if not state:
            return 0
        return state.get('completed_total', 0) + sum(state.get('parts', {}).values())

def emit_transfer_bytes_snapshot(transfer_id):
    if not TRANSFER_BYTES_CONFIG.get('enabled', True):
        return
    total = get_transfer_bytes_total(transfer_id)
    socketio.emit('speed_update', {
        'transfer_id': transfer_id,
        'transferred_bytes': total,
        'transferred_human': _human_readable_size(total)
    })

def _parse_rsync_progress_bytes(text):
    if not text:
        return None
    match = RSYNC_PROGRESS_BYTES_RE.match(text.strip())
    if not match:
        return None
    try:
        return int(match.group(1).replace(',', ''))
    except Exception:
        return None

def _consume_progress_text(buffer, text, transfer_id, part_id):
    if not text:
        return buffer
    buffer = (buffer or '') + text
    while True:
        idx_r = buffer.find('\r')
        idx_n = buffer.find('\n')
        idx = idx_r if idx_n == -1 else (idx_n if idx_r == -1 else min(idx_r, idx_n))
        if idx == -1:
            break
        line = buffer[:idx]
        buffer = buffer[idx + 1:]
        bytes_val = _parse_rsync_progress_bytes(line)
        if bytes_val is not None:
            update_transfer_bytes_part(transfer_id, part_id, bytes_val)
    if len(buffer) > 8192:
        buffer = buffer[-8192:]
    return buffer

def _append_rsync_progress_opts(rsync_opts):
    if TRANSFER_BYTES_CONFIG.get('enabled', True) and '--info=progress2' not in rsync_opts:
        rsync_opts.append('--info=progress2')

def _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id):
    import subprocess
    import os
    import signal

    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        bufsize=0,
        preexec_fn=os.setsid
    )

    register_transfer_process(transfer_id, {
        'type': 'subprocess',
        'process': process
    })

    buffer = ''
    try:
        stdout = process.stdout
        while True:
            if stdout is None:
                break
            try:
                ready, _, _ = select.select([stdout], [], [], 0.2)
            except Exception:
                ready = []
            if ready:
                try:
                    chunk = os.read(stdout.fileno(), 4096)
                except Exception:
                    chunk = b''
                if chunk:
                    buffer = _consume_progress_text(buffer, chunk.decode('utf-8', errors='ignore'), transfer_id, part_id)
                else:
                    if process.poll() is not None:
                        break
            if process.poll() is not None:

                try:
                    while True:
                        chunk = os.read(stdout.fileno(), 4096)
                        if not chunk:
                            break
                        buffer = _consume_progress_text(buffer, chunk.decode('utf-8', errors='ignore'), transfer_id, part_id)
                except Exception:
                    pass
                break
        return_code = process.wait()
    except KeyboardInterrupt:
        try:
            os.killpg(os.getpgid(process.pid), signal.SIGTERM)
            process.wait(timeout=2)
        except Exception:
            try:
                os.killpg(os.getpgid(process.pid), signal.SIGKILL)
                process.wait()
            except Exception:
                pass
        raise Exception("ä¼ è¾“è¢«ç”¨æˆ·å–æ¶ˆ")
    finally:
        finalize_transfer_bytes_part(transfer_id, part_id)

    return return_code

def _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id):
    stdin, stdout, stderr = ssh.exec_command(remote_cmd)
    register_transfer_process(transfer_id, {'type': 'ssh', 'channel': stdout.channel})

    channel = stdout.channel
    buffer = ''
    err_buf = ''
    max_err = 8192

    while True:
        if channel.recv_ready():
            chunk = channel.recv(4096)
            if chunk:
                buffer = _consume_progress_text(buffer, chunk.decode('utf-8', errors='ignore'), transfer_id, part_id)
        if channel.recv_stderr_ready():
            chunk = channel.recv_stderr(4096)
            if chunk:
                err_buf += chunk.decode('utf-8', errors='ignore')
                if len(err_buf) > max_err:
                    err_buf = err_buf[-max_err:]
        if channel.exit_status_ready() and not channel.recv_ready() and not channel.recv_stderr_ready():
            break
        time.sleep(0.1)

    exit_status = channel.recv_exit_status()
    finalize_transfer_bytes_part(transfer_id, part_id)
    return exit_status, err_buf


LOG_FILE_PATH = os.path.join(BASE_DIR, 'transfer.log')
_log_file_lock = threading.Lock()
LOG_MAX_LINES = 10000

def _count_log_lines(path: str) -> int:
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            return sum(1 for _ in f)
    except FileNotFoundError:
        return 0
    except Exception:
        return 0

def clear_log_if_too_large(max_lines: int = None) -> bool:
    limit = max_lines if isinstance(max_lines, int) and max_lines > 0 else LOG_MAX_LINES
    try:
        with _log_file_lock:
            if _count_log_lines(LOG_FILE_PATH) >= limit:
                with open(LOG_FILE_PATH, 'w', encoding='utf-8') as f:
                    f.write('')
                return True
    except Exception:
        pass
    return False

def _normalize_ip_for_log(server_ip: str) -> str:
    """Normalize local aliases to the real host IP; leave others unchanged."""
    try:
        return TURBOFILE_HOST_IP if is_local_server(server_ip) else server_ip
    except Exception:
        return server_ip


def _join_target_full_path_for_log(target_server: str, base_path: str, name: str) -> str:
    """Build the full target path by server type (Windows/POSIX)."""
    try:
        if is_windows_server(target_server):
            import ntpath
            return ntpath.join(base_path, name)
        else:
            base = base_path.rstrip('/\\')
            return f"{base}/{name}"
    except Exception:

        return f"{base_path}/{name}"

def _get_client_ip() -> str:
    """Extract client IP (proxy-aware)."""
    try:
        import re as _re
        def _extract_ipv4(s: str):
            if not s:
                return None
            first = s.split(',')[0].strip()
            m = _re.search(r'(\d{1,3}(?:\.\d{1,3}){3})', first)
            return m.group(1) if m else None

        candidates = [
            request.headers.get('X-Forwarded-For', ''),
            request.headers.get('X-Real-IP', ''),
            request.remote_addr
        ]
        for c in candidates:
            ip = _extract_ipv4(c)
            if ip:
                return ip
    except Exception:
        pass
    return 'æœªçŸ¥'

def _hhmmss_to_seconds(time_str: str) -> float:
    try:
        parts = str(time_str).split(':')
        if len(parts) == 3:
            h, m, s = parts
            return int(h) * 3600 + int(m) * 60 + float(s)
    except Exception:
        pass
    return 0.0


def append_transfer_log_record(source_ip: str,
                               target_ip: str,
                               source_path: str,
                               target_full_path: str,
                               duration_sec: float,
                               status: str,
                               error: str = "",
                               client_ip: str = "",
                               mode: str = "",
                               file_name: str = "",
                               action: str = "transfer") -> None:
    """Write a transfer record as a log line.
    Fields: timestamp, action, client_ip, source_ip, target_ip, source_path, target_path, file, mode, duration_sec, status, error
    """
    record = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'action': action or 'transfer',
        'client_ip': client_ip or 'æœªçŸ¥',
        'source_ip': _normalize_ip_for_log(source_ip),
        'target_ip': _normalize_ip_for_log(target_ip),
        'source_path': source_path,
        'target_path': target_full_path,
        'file': file_name or '',
        'mode': mode or '',
        'duration_sec': round(float(duration_sec), 3),
        'status': 'success' if status.lower() == 'success' else 'failure'
    }
    if error:
        record['error'] = str(error)

    line = json.dumps(record, ensure_ascii=False)
    try:
        with _log_file_lock:
            with open(LOG_FILE_PATH, 'a', encoding='utf-8') as f:
                f.write(line + "\n")
    except Exception as _:

        pass


class SpeedSimulator:
    def __init__(self):
        self.transfer_speeds = {}
        self.lock = threading.Lock()

    def init_transfer_speed(self, transfer_id, min_speed: float = 110.0, max_speed: float = 114.0):
        """Initialize transfer speed; allow scenario-specific ranges."""
        with self.lock:

            initial_speed = random.uniform(min_speed, max_speed)
            self.transfer_speeds[transfer_id] = {
                'current_speed': initial_speed,
                'last_update': time.time(),
                'trend': random.choice(['up', 'down', 'stable']),
                'trend_duration': 0,
                'min_speed': min_speed,
                'max_speed': max_speed
            }

    def get_simulated_speed(self, transfer_id):
        """Get simulated transfer speed; supports per-transfer ranges."""
        with self.lock:
            if transfer_id not in self.transfer_speeds:
                self.init_transfer_speed(transfer_id)

            speed_data = self.transfer_speeds[transfer_id]
            current_time = time.time()


            min_s = speed_data.get('min_speed', 110.0)
            max_s = speed_data.get('max_speed', 114.0)
            width = max(0.1, max_s - min_s)
            edge = max(0.2, 0.25 * width)


            if current_time - speed_data['last_update'] >= 0.1:
                speed_data['last_update'] = current_time
                speed_data['trend_duration'] += 1


                if speed_data['trend_duration'] >= 20:
                    speed_data['trend'] = random.choice(['up', 'down', 'stable'])
                    speed_data['trend_duration'] = 0

                current_speed = speed_data['current_speed']

                if speed_data['trend'] == 'up':
                    change = random.uniform(0.05 * width, 0.15 * width)
                    new_speed = min(max_s, current_speed + change)
                    if new_speed >= max_s - edge:
                        speed_data['trend'] = 'down'
                elif speed_data['trend'] == 'down':
                    change = random.uniform(0.05 * width, 0.15 * width)
                    new_speed = max(min_s, current_speed - change)
                    if new_speed <= min_s + edge:
                        speed_data['trend'] = 'up'
                else:  # stable
                    change = random.uniform(-0.05 * width, 0.05 * width)
                    new_speed = max(min_s, min(max_s, current_speed + change))

                speed_data['current_speed'] = new_speed

            return f"{speed_data['current_speed']:.1f} MB/s"

    def cleanup_transfer(self, transfer_id):
        """Clear transfer speed data."""
        with self.lock:
            if transfer_id in self.transfer_speeds:
                del self.transfer_speeds[transfer_id]


speed_simulator = SpeedSimulator()


class TransferTimeTracker:
    def __init__(self):
        self.transfer_start_times = {}
        self.lock = threading.Lock()

    def start_transfer(self, transfer_id):
        """Start transfer timing."""
        with self.lock:
            self.transfer_start_times[transfer_id] = time.time()

    def get_elapsed_time(self, transfer_id):
        """Get elapsed time."""
        with self.lock:
            if transfer_id in self.transfer_start_times:
                elapsed = time.time() - self.transfer_start_times[transfer_id]
                return self.format_time(elapsed)
            return "00:00:00"

    def end_transfer(self, transfer_id):
        """Stop transfer timing."""
        with self.lock:
            if transfer_id in self.transfer_start_times:
                elapsed = time.time() - self.transfer_start_times[transfer_id]
                del self.transfer_start_times[transfer_id]
                return self.format_time(elapsed)
            return "00:00:00"

    def format_time(self, seconds):
        """Format elapsed time."""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"


time_tracker = TransferTimeTracker()


class ProgressManager:
    def __init__(self):
        self.transfer_progress = {}
        self.progress_lock = threading.Lock()

    def init_transfer(self, transfer_id, total_files, total_bytes=0):
        """Initialize transfer progress."""
        with self.progress_lock:
            self.transfer_progress[transfer_id] = {
                'total_files': total_files,
                'completed_files': 0,
                'failed_files': 0,
                'total_bytes': total_bytes,
                'transferred_bytes': 0,
                'file_progress': {},
                'last_update_time': time.time()
            }

    def update_file_progress(self, transfer_id, file_name, percentage, bytes_transferred=0, speed=''):
        """Update progress for a single file."""
        with self.progress_lock:
            if transfer_id not in self.transfer_progress:
                return

            progress = self.transfer_progress[transfer_id]
            progress['file_progress'][file_name] = {
                'percentage': percentage,
                'bytes_transferred': bytes_transferred,
                'speed': speed
            }


            completed_files = progress['completed_files']
            total_files = progress['total_files']


            current_file_contribution = 0
            for fname, fprogress in progress['file_progress'].items():
                if fprogress['percentage'] < 100:
                    current_file_contribution += fprogress['percentage'] / 100

            overall_percentage = int(((completed_files + current_file_contribution) / total_files) * 100)
            overall_percentage = min(100, max(0, overall_percentage))


            current_time = time.time()
            if current_time - progress['last_update_time'] >= 0.5:
                progress['last_update_time'] = current_time


                simulated_speed = speed_simulator.get_simulated_speed(transfer_id)
                elapsed_time = time_tracker.get_elapsed_time(transfer_id)


                pass

    def complete_file(self, transfer_id, file_name, success=True):
        """Mark file transfer complete."""
        with self.progress_lock:
            if transfer_id not in self.transfer_progress:
                return

            progress = self.transfer_progress[transfer_id]
            if success:
                progress['completed_files'] += 1
            else:
                progress['failed_files'] += 1


            if file_name in progress['file_progress']:
                del progress['file_progress'][file_name]


            pass

    def cleanup_transfer(self, transfer_id):
        """Clear transfer progress records."""
        with self.progress_lock:
            if transfer_id in self.transfer_progress:
                del self.transfer_progress[transfer_id]

progress_manager = ProgressManager()

def _is_transfer_process_active(proc_info):
    """Check whether a recorded transfer process is still running."""
    try:
        if not proc_info:
            return False

        if isinstance(proc_info, list):
            return any(_is_transfer_process_active(p) for p in proc_info)
        ptype = proc_info.get('type')
        if ptype == 'subprocess':
            proc = proc_info.get('process')
            return proc is not None and proc.poll() is None
        if ptype == 'ssh':
            ch = proc_info.get('channel')
            return ch is not None and not ch.exit_status_ready()
    except Exception:
        return False
    return False


def _cleanup_transfer_state(transfer_id):
    """Clean transfer state to avoid zombie tasks."""
    if transfer_id in active_transfers:
        del active_transfers[transfer_id]
    with TRANSFER_PROCESS_LOCK:
        transfer_processes.pop(transfer_id, None)
    cleanup_transfer_bytes(transfer_id)
    progress_manager.cleanup_transfer(transfer_id)
    speed_simulator.cleanup_transfer(transfer_id)
    cleanup_transfer_bytes(transfer_id)


def start_transfer_watchdog():
    """Background cleaner: purge timed-out tasks with no active processes."""
    def watchdog():
        while True:
            try:
                time.sleep(TRANSFER_WATCHDOG_INTERVAL)
                now = datetime.now()
                stale_ids = []
                for tid, meta in list(active_transfers.items()):
                    start_ts = meta.get('start_time')
                    try:
                        age = (now - start_ts).total_seconds() if isinstance(start_ts, datetime) else max(0, time.time() - float(start_ts))
                    except Exception:
                        age = 0

                    if age < STALE_TRANSFER_TIMEOUT:
                        continue

                    proc_info = get_transfer_processes_snapshot(tid)
                    if proc_info and _is_transfer_process_active(proc_info):

                        continue


                    stale_ids.append(tid)

                for tid in stale_ids:
                    print(f"[WATCHDOG] æ¸…ç†ç–‘ä¼¼åƒµå°¸ä¼ è¾“ä»»åŠ¡: {tid}")
                    _cleanup_transfer_state(tid)
            except Exception as e:
                print(f"[WATCHDOG] ä¼ è¾“æ¸…ç†å™¨å¼‚å¸¸: {e}")
                continue

    t = threading.Thread(target=watchdog, daemon=True)
    t.start()

start_transfer_watchdog()

class SSHManager:
    def __init__(self):
        self.connections = {}
        self.connection_pool_size = 3
        self.connection_pools = {}

    def get_connection(self, server_ip):
        """Get an SSH connection using the pool."""

        if server_ip not in self.connection_pools:
            self.connection_pools[server_ip] = []


        pool = self.connection_pools[server_ip]
        for i, ssh in enumerate(pool):
            if ssh and ssh.get_transport() and ssh.get_transport().is_active():

                pool.append(pool.pop(i))
                return ssh
            else:

                if ssh:
                    try:
                        ssh.close()
                    except:
                        pass
                pool.remove(ssh)


        try:
            ssh = paramiko.SSHClient()
            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            server_config = SERVERS[server_ip]


            connect_kwargs = {
                'hostname': server_ip,
                'username': server_config["user"],
                'port': server_config.get("port", 22),
                'timeout': 5,
                'compress': False,
                'look_for_keys': True,
                'allow_agent': True,
                'sock': None,
                'gss_auth': False,
                'gss_kex': False,
                'gss_deleg_creds': False,
                'gss_host': None,
                'banner_timeout': 5,
                'auth_timeout': 5,
                'channel_timeout': 5
            }


            try:
                ssh.connect(**connect_kwargs)
                print(f"âœ… ä½¿ç”¨å¯†é’¥è¿æ¥åˆ°æœåŠ¡å™¨ {server_ip}")
            except:

                connect_kwargs['password'] = server_config["password"]
                ssh.connect(**connect_kwargs)
                print(f"âœ… ä½¿ç”¨å¯†ç è¿æ¥åˆ°æœåŠ¡å™¨ {server_ip}")


            if len(pool) >= self.connection_pool_size:

                old_ssh = pool.pop(0)
                try:
                    old_ssh.close()
                except:
                    pass

            pool.append(ssh)
            return ssh

        except Exception as e:
            print(f"âŒ è¿æ¥æœåŠ¡å™¨ {server_ip} å¤±è´¥: {e}")
            return None

    def execute_command(self, server_ip, command):
        """Execute a remote command and return (stdout, stderr, exit_code)."""
        ssh = self.get_connection(server_ip)
        if not ssh:
            return None, f"æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ {server_ip}", -1


        is_win = is_windows_server(server_ip)
        encoding = 'gbk' if is_win else 'utf-8'

        try:
            stdin, stdout, stderr = ssh.exec_command(command)

            output = stdout.read().decode(encoding, errors='ignore')
            error = stderr.read().decode(encoding, errors='ignore')
            try:
                exit_code = stdout.channel.recv_exit_status()
            except Exception:
                exit_code = 0 if not error else 1
            return output, error, exit_code
        except Exception as e:

            print(f"âš ï¸  SSHè¿æ¥å¼‚å¸¸ï¼Œå°è¯•é‡æ–°è¿æ¥åˆ° {server_ip}: {e}")
            if server_ip in self.connections:
                try:
                    self.connections[server_ip].close()
                except:
                    pass
                del self.connections[server_ip]


            ssh = self.get_connection(server_ip)
            if ssh:
                try:
                    stdin, stdout, stderr = ssh.exec_command(command)
                    output = stdout.read().decode(encoding, errors='ignore')
                    error = stderr.read().decode(encoding, errors='ignore')
                    try:
                        exit_code = stdout.channel.recv_exit_status()
                    except Exception:
                        exit_code = 0 if not error else 1
                    return output, error, exit_code
                except Exception as retry_e:
                    return None, f"é‡è¿åä»ç„¶å¤±è´¥: {str(retry_e)}", -1

            return None, str(e), -1

ssh_manager = SSHManager()
RUN_TASKS = {}
RUN_TASKS_LOCK = threading.Lock()

def get_ssh_command_with_port(server_ip, fast_ssh=True):
    """Build an SSH command string with custom port support."""
    server_config = SERVERS[server_ip]
    port = server_config.get("port", 22)

    ssh_cmd_parts = [
        "ssh",
        "-p", str(port),
        "-o", "StrictHostKeyChecking=no",
        "-o", "PasswordAuthentication=yes",
        "-o", "ConnectTimeout=10",
        "-o", "ServerAliveInterval=30",
        "-o", "ServerAliveCountMax=3",
        "-o", "TCPKeepAlive=yes",
        "-o", "ControlMaster=auto",
        "-o", f"ControlPath=/tmp/ssh-%r@%h:{port}",
        "-o", "ControlPersist=300"
    ]

    if fast_ssh:
        ssh_cmd_parts.extend([
            "-o", "Compression=no",
            "-o", "Ciphers=aes128-ctr",
            "-o", "MACs=umac-64@openssh.com"
        ])

    return " ".join(ssh_cmd_parts)

def is_windows_server(server_ip):
    """Return whether the server is Windows."""
    server_config = SERVERS.get(server_ip, {})
    is_windows = server_config.get("os_type") == "windows"
    print(f"ğŸ” æ£€æŸ¥æ˜¯å¦ä¸ºWindowsæœåŠ¡å™¨: {server_ip} -> {is_windows}")
    return is_windows

def convert_windows_path_to_cygwin(windows_path):
    """Convert Windows path to Cygwin format.
    Example: C:\\Users\\warrior\\Documents -> /cygdrive/c/Users/warrior/Documents
    """
    import re

    match = re.match(r'^([A-Za-z]):[/\\](.*)$', windows_path)
    if match:
        drive = match.group(1).lower()
        path = match.group(2).replace('\\', '/')
        return f"/cygdrive/{drive}/{path}"

    return windows_path.replace('\\', '/')

def convert_cygwin_path_to_windows(cygwin_path):
    """Convert Cygwin path to Windows format.
    Example: /cygdrive/c/Users/warrior/Documents -> C:/Users/warrior/Documents
    """
    import re
    match = re.match(r'^/cygdrive/([a-z])/(.*)$', cygwin_path)
    if match:
        drive = match.group(1).upper()
        path = match.group(2)
        return f"{drive}:/{path}"
    return cygwin_path


def normalize_windows_path_for_transfer(p: str) -> str:
    try:
        if not p:
            return p
        s = p.replace('\\', '/')
        import re

        if s.startswith('/') and re.match(r'^/[A-Za-z]:/?$', s):
            s = s[1:]

        if re.match(r'^[A-Za-z]:$', s):
            s = s + '/'
        return s
    except Exception:
        return p


def normalize_windows_path_for_cmd(p: str) -> str:
    """Convert a path to Windows CMD format (backslashes)."""
    try:
        if not p:
            return p

        s = normalize_windows_path_for_transfer(p)

        s = s.replace('/', '\\')
        return s
    except Exception:
        return p





def get_default_path(server_ip):
    """Get the default server path."""
    server_config = SERVERS.get(server_ip, {})


    if is_windows_server(server_ip):
        try:

            output, error, _ = ssh_manager.execute_command(server_ip, 'echo %USERPROFILE%')
            if output and not error:

                user_profile = output.strip().replace('\\', '/')
                print(f"ğŸ  Windowsç”¨æˆ·ä¸»ç›®å½•: {user_profile}")
                return user_profile
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è·å–Windowsç”¨æˆ·ä¸»ç›®å½•: {e}")


        return "C:/"


    if server_ip == "10.190.21.253":
        return "/var/services/homes/Algorithm"


    user = server_config.get("user", "th")
    return f"/home/{user}"

class ParallelTransferManager:
    def __init__(self):
        self.active_transfers = {}
        self.transfer_stats = {}

    def get_file_size(self, server_ip, file_path):
        """Get file size."""
        if is_local_server(server_ip):
            try:
                return os.path.getsize(file_path)
            except:
                return 0
        else:

            output, error, _ = ssh_manager.execute_command(server_ip, f"stat -c%s {shlex.quote(file_path)} 2>/dev/null || echo 0")
            try:
                return int(output.strip())
            except:
                return 0

    def analyze_directory_structure(self, source_server, dir_path):
        """Analyze directory structure and return child file info."""
        all_files = []

        print(f"ğŸ” åˆ†æç›®å½•ç»“æ„: {source_server}:{dir_path}")


        is_local_source = is_local_server(source_server)

        if is_local_source:

            print(f"ğŸ“ æœ¬åœ°ç›®å½•åˆ†æ: {dir_path}")
            try:
                for root, dirs, files in os.walk(dir_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        try:
                            file_size = os.path.getsize(file_path)
                            relative_path = os.path.relpath(file_path, dir_path)
                            all_files.append({
                                'path': file_path,
                                'name': relative_path,
                                'size': file_size,
                                'is_directory': False
                            })
                        except Exception as e:
                            print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {file_path}: {e}")
                            continue
                print(f"âœ… æœ¬åœ°ç›®å½•åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
            except Exception as e:
                print(f"âŒ æœ¬åœ°ç›®å½•åˆ†æå¤±è´¥: {e}")
        else:

            print(f"ğŸŒ è¿œç¨‹ç›®å½•åˆ†æ: {source_server}:{dir_path}")
            try:

                cmd = f"find {shlex.quote(dir_path)} -type f -exec stat -c '%n %s' {{}} \\;"
                print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {cmd}")
                output, error, _ = ssh_manager.execute_command(source_server, cmd)

                if error:
                    print(f"âš ï¸ å‘½ä»¤æ‰§è¡Œè­¦å‘Š: {error}")

                if output:
                    print(f"ğŸ“„ å‘½ä»¤è¾“å‡ºé•¿åº¦: {len(output)} å­—ç¬¦")
                    lines = output.strip().split('\n')
                    print(f"ğŸ“„ è¾“å‡ºè¡Œæ•°: {len(lines)}")

                    for line in lines:
                        if line.strip():
                            parts = line.rsplit(' ', 1)
                            if len(parts) == 2:
                                file_path, size_str = parts
                                try:
                                    file_size = int(size_str)
                                    relative_path = os.path.relpath(file_path, dir_path)
                                    all_files.append({
                                        'path': file_path,
                                        'name': relative_path,
                                        'size': file_size,
                                        'is_directory': False
                                    })
                                except Exception as e:
                                    print(f"âš ï¸ è§£ææ–‡ä»¶ä¿¡æ¯å¤±è´¥ {line}: {e}")
                                    continue
                    print(f"âœ… è¿œç¨‹ç›®å½•åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
                else:
                    print(f"âš ï¸ å‘½ä»¤æ— è¾“å‡ºï¼Œå¯èƒ½ç›®å½•ä¸ºç©ºæˆ–æ— æƒé™")
            except Exception as e:
                print(f"âŒ è¿œç¨‹ç›®å½•åˆ†æå¤±è´¥: {e}")

        return all_files

    def categorize_files(self, source_server, source_files, transfer_id=None):
        """Classify files into small/large groups and analyze directory structure."""
        small_files = []
        large_files = []
        directory_files = []

        threshold_bytes = PARALLEL_TRANSFER_CONFIG['small_file_threshold_mb'] * 1024 * 1024

        print(f"ğŸ” å¼€å§‹æ–‡ä»¶åˆ†ç±»ï¼ŒæºæœåŠ¡å™¨: {source_server}, æ–‡ä»¶æ•°é‡: {len(source_files)}")

        try:
            for i, file_info in enumerate(source_files):
                print(f"ğŸ“ å¤„ç†æ–‡ä»¶ {i+1}/{len(source_files)}: {file_info['name']} (ç›®å½•: {file_info['is_directory']})")

                if file_info['is_directory']:

                    print(f"ğŸ” åˆ†æç›®å½•: {file_info['path']}")


                    if transfer_id:
                        emit_transfer_log(transfer_id, f'ğŸ“ æ­£åœ¨åˆ†æç›®å½• {file_info["name"]} çš„ç»“æ„...')

                    try:

                        if PARALLEL_TRANSFER_CONFIG['fast_mode']:

                            if transfer_id:
                                emit_transfer_log(transfer_id, f'âš¡ å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡ç›®å½• {file_info["name"]} çš„è¯¦ç»†åˆ†æ')


                            large_files.append({
                                **file_info,
                                'sub_files_count': 1,
                                'total_size': 0
                            })
                        else:

                            dir_files = self.analyze_directory_structure(source_server, file_info['path'])
                            directory_files.extend(dir_files)

                            print(f"âœ… ç›®å½• {file_info['name']} åŒ…å« {len(dir_files)} ä¸ªæ–‡ä»¶")


                            if len(dir_files) > PARALLEL_TRANSFER_CONFIG['max_analysis_files']:
                                if transfer_id:
                                    emit_transfer_log(transfer_id, f'âš ï¸ ç›®å½• {file_info["name"]} åŒ…å« {len(dir_files)} ä¸ªæ–‡ä»¶ï¼Œå»ºè®®å¯ç”¨å¿«é€Ÿæ¨¡å¼ä»¥æé«˜æ€§èƒ½')


                            if transfer_id:
                                emit_transfer_log(transfer_id, f'âœ… ç›®å½• {file_info["name"]} åˆ†æå®Œæˆï¼ŒåŒ…å« {len(dir_files)} ä¸ªæ–‡ä»¶')


                            large_files.append({
                                **file_info,
                                'sub_files_count': len(dir_files),
                                'total_size': sum(f['size'] for f in dir_files)
                            })
                    except Exception as e:
                        print(f"âŒ åˆ†æç›®å½• {file_info['name']} å¤±è´¥: {e}")


                        if transfer_id:
                            emit_transfer_log(transfer_id, f'âš ï¸ ç›®å½• {file_info["name"]} åˆ†æå¤±è´¥: {str(e)}')


                        large_files.append({
                            **file_info,
                            'sub_files_count': 0,
                            'total_size': 0
                        })
                else:
                    try:
                        file_size = self.get_file_size(source_server, file_info['path'])
                        file_info['size'] = file_size

                        print(f"ğŸ“„ æ–‡ä»¶ {file_info['name']} å¤§å°: {file_size} å­—èŠ‚")

                        if file_size < threshold_bytes:
                            small_files.append(file_info)
                        else:
                            large_files.append(file_info)
                    except Exception as e:
                        print(f"âŒ è·å–æ–‡ä»¶ {file_info['name']} å¤§å°å¤±è´¥: {e}")

                        large_files.append(file_info)

            print(f"âœ… æ–‡ä»¶åˆ†ç±»å®Œæˆ: {len(small_files)}ä¸ªå°æ–‡ä»¶, {len(large_files)}ä¸ªå¤§æ–‡ä»¶/ç›®å½•, {len(directory_files)}ä¸ªå­æ–‡ä»¶")

        except Exception as e:
            print(f"âŒ æ–‡ä»¶åˆ†ç±»è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

            large_files = source_files.copy()
            small_files = []
            directory_files = []

        return small_files, large_files, directory_files

    def create_file_batches(self, files, batch_size=10):
        """Batch small files."""
        batches = []
        for i in range(0, len(files), batch_size):
            batches.append(files[i:i + batch_size])
        return batches

parallel_manager = ParallelTransferManager()


file_cache = {}
cache_timeout = 120
instant_cache_timeout = 300
BROWSE_PAGE_SIZE_DEFAULT = 400
BROWSE_PAGE_SIZE_MAX = 2000
BROWSE_PAGE_SIZE_MIN = 100

def _natural_sort_key(name: str):
    """Build a natural sort key (numbers by value, text case-insensitive)."""
    try:
        parts = re.split(r'(\d+)', name)
        return [int(p) if p.isdigit() else p.lower() for p in parts]
    except Exception:
        return [name.lower()]

def sort_file_items(items):
    """Sort WinSCP-style: directories first, then natural name order."""
    try:
        return sorted(
            items,
            key=lambda x: (
                0 if x.get('is_directory') else 1,
                _natural_sort_key(x.get('name', ''))
            )
        )
    except Exception:
        return items

def get_cache_key(server_ip, path, show_hidden):
    """Build cache key."""
    return f"{server_ip}:{path}:{show_hidden}"

def is_cache_valid(cache_entry):
    """Check whether cache is valid."""
    return time.time() - cache_entry['timestamp'] < cache_timeout

def get_cached_listing(server_ip, path, show_hidden):
    """Get cached file list."""
    cache_key = get_cache_key(server_ip, path, show_hidden)
    if cache_key in file_cache:
        cache_entry = file_cache[cache_key]
        if is_cache_valid(cache_entry):
            return cache_entry['data']
    return None

def set_cached_listing(server_ip, path, show_hidden, data):
    """Set file list cache."""
    cache_key = get_cache_key(server_ip, path, show_hidden)
    file_cache[cache_key] = {
        'data': data,
        'timestamp': time.time()
    }


    current_time = time.time()
    expired_keys = [k for k, v in file_cache.items()
                   if current_time - v['timestamp'] > cache_timeout]
    for key in expired_keys:
        del file_cache[key]

def clear_cached_listing(server_ip, path, show_hidden=None):
    """Clear cache for a path."""
    if show_hidden is None:

        keys_to_remove = []
        for cache_key in file_cache.keys():
            if cache_key.startswith(f"{server_ip}:{path}:"):
                keys_to_remove.append(cache_key)

        for key in keys_to_remove:
            del file_cache[key]

        return len(keys_to_remove)
    else:

        cache_key = get_cache_key(server_ip, path, show_hidden)
        if cache_key in file_cache:
            del file_cache[cache_key]
            return 1
        return 0

def clear_all_cache():
    """Clear all caches."""
    cache_count = len(file_cache)
    file_cache.clear()
    return cache_count

def is_winscp_hidden_file(name, permissions="", path="/"):
    """Decide whether to hide a file per WinSCP rules.

    Args:
        name: file name
        permissions: permission string (ls -l format)
        path: current directory path

    Returns:
        bool: True to hide, False to show
    """

    if name.startswith('.'):
        return True


    system_symlinks = {
        'bin', 'sbin', 'lib', 'lib32', 'lib64', 'libx32'
    }
    if name in system_symlinks:
        return True


    system_dirs = {
        'proc', 'sys', 'dev', 'run', 'boot', 'etc', 'var', 'tmp',
        'lost+found', 'cdrom', 'media', 'mnt', 'opt', 'srv', 'usr'
    }
    if name in system_dirs:
        return True


    system_files = {
        'swapfile', 'vmlinuz', 'initrd.img'
    }
    if name in system_files:
        return True


    if name.startswith('.Trash-'):
        return True


    if name == 'root' and path != '/':
        return True


    if name == 'home' and path != '/':
        return True


    if name == 'snap':
        return True



    if '/Work' in path or path.endswith('/Work'):

        work_hidden_dirs = {
            'home', 'root', 'snap', 'boot', 'etc', 'var', 'usr', 'opt',
            'proc', 'sys', 'dev', 'run', 'tmp', 'media', 'mnt', 'srv',
            'lost+found', 'cdrom'
        }
        if name in work_hidden_dirs:
            return True


        if name in {'bin', 'sbin', 'lib', 'lib32', 'lib64', 'libx32'}:
            return True

    return False

def get_directory_listing(server_ip, path=None, show_hidden=False):
    """Get a remote directory listing.

    Args:
        server_ip: server IP
        path: directory path
        show_hidden: include hidden files (WinSCP rules)
    """

    if path is None:
        path = get_default_path(server_ip)


    cached_result = get_cached_listing(server_ip, path, show_hidden)
    if cached_result is not None:
        return cached_result
    if is_local_server(server_ip):

        try:
            items = []
            for item in os.listdir(path):
                if not show_hidden and item.startswith('.'):
                    continue

                item_path = os.path.join(path, item)
                is_dir = os.path.isdir(item_path)
                size = os.path.getsize(item_path) if not is_dir else 0
                mtime = os.path.getmtime(item_path)

                items.append({
                    "name": item,
                    "path": item_path,
                    "is_directory": is_dir,
                    "size": size,
                    "modified": datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
                })
            items = sort_file_items(items)
            set_cached_listing(server_ip, path, show_hidden, items)
            return items
        except Exception:
            return []
    else:

        # Return whether the server is Windows.
        if is_windows_server(server_ip):


            import re
            normalized_path = path or ''

            if normalized_path.startswith('/') and re.match(r'^/[A-Za-z]:', normalized_path):
                normalized_path = normalized_path[1:]

            if re.match(r'^[A-Za-z]:$', normalized_path):
                normalized_path = normalized_path + '/'

            win_path = normalized_path.replace('/', '\\')

            dir_flags = "/-c"
            if show_hidden:
                dir_flags = "/a /-c"
            command = f'dir "{win_path}" {dir_flags}'

            output, error, _ = ssh_manager.execute_command(server_ip, command)

            if error and "æ‰¾ä¸åˆ°æ–‡ä»¶" not in error and "File Not Found" not in error:
                print(f"Windows dirå‘½ä»¤é”™è¯¯: {error}")
                return []

            items = []
            lines = output.strip().split('\n')


            for line in lines:
                line = line.strip()
                if not line:
                    continue


                if 'Directory of' in line or 'ä¸ªæ–‡ä»¶' in line or 'ä¸ªç›®å½•' in line or 'File(s)' in line or 'Dir(s)' in line or 'bytes free' in line or 'çš„ç›®å½•' in line or 'å¯ç”¨å­—èŠ‚' in line:
                    continue






                import re

                match = re.match(r'(\d{2,4}[-/]\d{2}[-/]\d{2,4})\s+(ä¸Šåˆ|ä¸‹åˆ)?\s*(\d{2}:\d{2})\s+(<DIR>|<JUNCTION>|\d[\d,]*)\s+(.+)$', line)

                if match:
                    date_str = match.group(1)
                    am_pm = match.group(2) or ''
                    time_str = match.group(3)
                    size_or_dir = match.group(4)
                    name = match.group(5).strip()


                    if name in ['.', '..']:
                        continue


                    is_directory = (size_or_dir in ['<DIR>', '<JUNCTION>'])


                    if is_directory:
                        size = 0
                    else:
                        try:
                            size = int(size_or_dir.replace(',', ''))
                        except:
                            size = 0


                    base_path = normalized_path if 'normalized_path' in locals() and normalized_path else path
                    full_path = f"{base_path.rstrip('/')}/{name}".replace('\\', '/')


                    full_time = f"{am_pm} {time_str}".strip() if am_pm else time_str

                    items.append({
                        "name": name,
                        "path": full_path,
                        "is_directory": is_directory,
                        "size": size,
                        "modified": f"{date_str} {full_time}"
                    })

            items = sort_file_items(items)
            set_cached_listing(server_ip, path, show_hidden, items)
            return items
        else:



            command = f"ls -la {shlex.quote(path)} | tail -n +2"

            output, error, _ = ssh_manager.execute_command(server_ip, command)

            if error:
                return []

            items = []


























            for line in output.strip().split('\n'):



                if not line:
                    continue

                parts = line.split()
                if len(parts) < 9:
                    continue

                permissions = parts[0]
                size = parts[4]
                date_parts = parts[5:8]
                name = ' '.join(parts[8:])

                if not show_hidden and name.startswith('.'):
                    continue


                if name in ['.', '..']:
                    continue


                if not show_hidden:
                    if is_winscp_hidden_file(name, permissions, path):
                        continue

                is_directory = permissions.startswith('d')

                items.append({
                    "name": name,
                    "path": os.path.join(path, name),
                    "is_directory": is_directory,
                    "size": int(size) if size.isdigit() else 0,
                    "modified": ' '.join(date_parts)
                })

            items = sort_file_items(items)
            set_cached_listing(server_ip, path, show_hidden, items)
            return items

def get_directory_listing_optimized(server_ip, path=None, show_hidden=False):
    """Optimized directory listing focused on response speed."""


    if path is None:
        path = get_default_path(server_ip)


    cached_result = get_cached_listing(server_ip, path, show_hidden)
    if cached_result is not None:
        return cached_result


    if is_local_server(server_ip):

        try:
            items = []

            with os.scandir(path) as entries:
                for entry in entries:
                    if not show_hidden and entry.name.startswith('.'):
                        continue

                    try:
                        stat_info = entry.stat()
                        is_dir = entry.is_dir()
                        size = 0 if is_dir else stat_info.st_size
                        mtime = stat_info.st_mtime

                        items.append({
                            "name": entry.name,
                            "path": os.path.join(path, entry.name),
                            "is_directory": is_dir,
                            "size": size,
                            "modified": datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
                        })
                    except (OSError, PermissionError):

                        continue

            items = sort_file_items(items)
            set_cached_listing(server_ip, path, show_hidden, items)
            return items
        except Exception:
            return []
    else:

        return get_directory_listing(server_ip, path, show_hidden)

def start_speed_update_timer(transfer_id, source_server, target_server):
    """Start the speed update timer to improve transfer performance."""
    def speed_updater():
        last_time_update = time.time()
        last_speed_update = time.time()
        last_bytes_update = time.time()

        while transfer_id in active_transfers:
            try:

                time.sleep(0.25)

                if transfer_id not in active_transfers:
                    break

                current_time = time.time()


                simulated_speed = None
                if current_time - last_speed_update >= 0.1:
                    simulated_speed = speed_simulator.get_simulated_speed(transfer_id)
                    last_speed_update = current_time


                elapsed_time = None
                if current_time - last_time_update >= 1.0:
                    elapsed_time = time_tracker.get_elapsed_time(transfer_id)
                    last_time_update = current_time

                transferred_human = None
                transferred_bytes = None
                if TRANSFER_BYTES_CONFIG.get('enabled', True) and current_time - last_bytes_update >= TRANSFER_BYTES_CONFIG.get('update_interval', 2.0):
                    transferred_bytes = get_transfer_bytes_total(transfer_id)
                    transferred_human = _human_readable_size(transferred_bytes)
                    last_bytes_update = current_time


                if simulated_speed is not None or elapsed_time is not None or transferred_human is not None:

                    is_local_source = is_local_server(source_server)
                    is_local_target = is_local_server(target_server)

                    if is_local_source and not is_local_target:
                        transfer_mode = 'local_to_remote'
                    elif not is_local_source and is_local_target:
                        transfer_mode = 'remote_to_local'
                    else:
                        transfer_mode = 'remote_to_remote'


                    update_data = {
                        'transfer_id': transfer_id,
                        'source_server': source_server,
                        'target_server': target_server,
                        'transfer_mode': transfer_mode
                    }


                    if simulated_speed is not None:
                        update_data['speed'] = simulated_speed
                    if elapsed_time is not None:
                        update_data['elapsed_time'] = elapsed_time
                    if transferred_human is not None:
                        update_data['transferred_bytes'] = transferred_bytes
                        update_data['transferred_human'] = transferred_human

                    socketio.emit('speed_update', update_data)

            except Exception as e:
                print(f"é€Ÿåº¦æ›´æ–°å™¨å‡ºé”™: {e}")
                break


    speed_thread = threading.Thread(target=speed_updater)
    speed_thread.daemon = True
    speed_thread.start()

def _normalize_batch_path(path: str) -> str:
    if not path:
        return ''
    return path.replace('\\', '/')

def _get_batch_parent(source_files, source_is_windows):
    parents = set()
    for file_info in source_files or []:
        path = _normalize_batch_path(file_info.get('path', ''))
        if not path:
            continue
        if source_is_windows:
            import ntpath
            parent = ntpath.dirname(path)
            if parent and parent.endswith(':'):
                parent += '/'
        else:
            parent = os.path.dirname(path) or '/'
        parents.add(_normalize_batch_path(parent))
    if len(parents) == 1:
        return parents.pop()
    return None

def _can_batch_transfer(transfer_mode, source_files, source_is_windows, source_server, target_server):
    if transfer_mode not in ('local_to_remote', 'remote_to_local', 'remote_to_remote'):
        return False
    if source_server == target_server:
        return False
    if not source_files or len(source_files) < 2:
        return False
    return bool(_get_batch_parent(source_files, source_is_windows))

def _build_batch_rsync_opts(source_is_windows=False, target_is_windows=False):
    rsync_opts = [
        '-a',
        '--inplace',
        '--whole-file',
        '--no-compress',
        '--numeric-ids',
        '--timeout=600',
        '-s',
        '--no-perms',
        '--no-owner',
        '--no-group',
        '--omit-dir-times',
    ]
    if source_is_windows or target_is_windows:
        rsync_opts.append('--iconv=UTF-8,UTF-8')
    _append_rsync_progress_opts(rsync_opts)
    return rsync_opts

def _delete_source_paths_batch(source_server, paths):
    if not paths:
        return True

    is_local = is_local_server(source_server)
    is_windows = is_windows_server(source_server)

    try:
        if is_local:
            try:
                subprocess.run(['rm', '-rf', '--', *paths], check=True)
                return True
            except Exception:
                ok = True
                for p in paths:
                    try:
                        if os.path.isdir(p):
                            shutil.rmtree(p)
                        else:
                            os.remove(p)
                    except Exception:
                        ok = False
                return ok

        if is_windows:
            try:
                path_pairs = []
                for p in paths:
                    win_p = normalize_windows_path_for_cmd(p)
                    path_pairs.append(win_p)
                ps_items = ",".join([f"'{_escape_pwsh_literal(win_p)}'" for win_p in path_pairs])
                ps_script = (
                    "$failed=@();"
                    f"$paths=@({ps_items});"
                    "foreach($p in $paths){"
                    "  if(Test-Path -LiteralPath $p){"
                    "    $err='';"
                    "    try{ Remove-Item -LiteralPath $p -Force -Recurse -ErrorAction Stop }catch{ $err=$_.Exception.Message }"
                    "    if(Test-Path -LiteralPath $p){"
                    "      if([string]::IsNullOrEmpty($err)){ $err='åˆ é™¤å¤±è´¥' }"
                    "      $failed += [pscustomobject]@{path=$p; error=$err}"
                    "    }"
                    "  }"
                    "}"
                    "if($failed.Count -gt 0){ $failed | ConvertTo-Json -Compress; exit 1 }"
                    "exit 0"
                )
                delete_cmd = f'powershell -NoProfile -Command "{ps_script}"'
                _, _, exit_code = ssh_manager.execute_command(source_server, delete_cmd)
                if exit_code == 0:
                    return True
            except Exception:
                pass

            ok = True
            for p in paths:
                try:
                    win_path = normalize_windows_path_for_cmd(p)
                    ps_path = win_path.replace("'", "''")
                    delete_cmd = (
                        "powershell -NoProfile -Command "
                        f"\"Remove-Item -LiteralPath '{ps_path}' -Force -Recurse -ErrorAction SilentlyContinue; "
                        f"if (Test-Path -LiteralPath '{ps_path}') {{ exit 1 }}\""
                    )
                    _, _, exit_code = ssh_manager.execute_command(source_server, delete_cmd)
                    if exit_code != 0:
                        ok = False
                except Exception:
                    ok = False
            return ok

        quoted_paths = " ".join([shlex.quote(p) for p in paths if p])
        if quoted_paths:
            rm_cmd_sudo = f"sudo -n rm -rf -- {quoted_paths}"
            _, _, exit_code = ssh_manager.execute_command(source_server, rm_cmd_sudo)
            if exit_code != 0:
                rm_cmd = f"rm -rf -- {quoted_paths}"
                _, _, exit_code = ssh_manager.execute_command(source_server, rm_cmd)
            if exit_code == 0:
                return True

        ok = True
        for p in paths:
            try:
                rm_cmd_sudo = f"sudo -n rm -rf {shlex.quote(p)}"
                _, _, exit_code = ssh_manager.execute_command(source_server, rm_cmd_sudo)
                if exit_code != 0:
                    rm_cmd = f"rm -rf {shlex.quote(p)}"
                    _, _, exit_code = ssh_manager.execute_command(source_server, rm_cmd)
                if exit_code != 0:
                    ok = False
            except Exception:
                ok = False
        return ok
    except Exception:
        return False

def _clear_transfer_listing_cache(source_server, target_server, source_files, target_path, mode):
    try:
        if target_server and target_path:
            clear_cached_listing(target_server, target_path)
    except Exception:
        pass

    if mode != 'move':
        return

    try:
        source_is_windows = is_windows_server(source_server)
        parent = _get_batch_parent(source_files, source_is_windows)
        if parent:
            clear_cached_listing(source_server, parent)
            return
        parents = set()
        for info in source_files or []:
            p = _normalize_batch_path(info.get('path', ''))
            if not p:
                continue
            if source_is_windows:
                import ntpath
                pp = ntpath.dirname(p)
                if pp and pp.endswith(':'):
                    pp += '/'
            else:
                pp = os.path.dirname(p) or '/'
            parents.add(_normalize_batch_path(pp))
        for pp in parents:
            clear_cached_listing(source_server, pp)
    except Exception:
        pass

def transfer_batch_instant(transfer_id, source_server, source_files, target_server, target_path, mode="copy", fast_ssh=True):
    """Batch transfer: combine same-directory files into one rsync to reduce overhead."""
    transfer_mode = determine_transfer_mode(source_server, target_server)
    source_is_windows = is_windows_server(source_server)
    target_is_windows = is_windows_server(target_server)

    if not _can_batch_transfer(transfer_mode, source_files, source_is_windows, source_server, target_server):
        return {'success': False, 'message': 'batch not applicable'}

    if transfer_mode == 'remote_to_remote' and source_server == target_server:
        return {'success': False, 'message': 'same server no rsync'}

    max_files = PARALLEL_TRANSFER_CONFIG.get('batch_max_files', 200)
    if max_files and len(source_files) > max_files:
        return {'success': False, 'message': 'batch size too large'}

    rsync_opts = _build_batch_rsync_opts(source_is_windows, target_is_windows)
    rsync_opts_str = ' '.join(rsync_opts)

    try:
        if transfer_mode == 'local_to_remote':
            target_user = SERVERS[target_server]['user']
            target_password = SERVERS[target_server].get('password')
            rsync_target_path = target_path
            if target_is_windows:
                normalized_target = normalize_windows_path_for_transfer(target_path)
                rsync_target_path = convert_windows_path_to_cygwin(normalized_target)

            ssh_cmd = RSYNC_SSH_CMD
            target_port = SERVERS[target_server].get('port', 22)
            if target_port != 22:
                ssh_cmd = f"{ssh_cmd} -p {target_port}"

            sources = [_normalize_batch_path(f.get('path', '')) for f in source_files]
            sources = [s for s in sources if s]
            if not sources:
                return {'success': False, 'message': 'empty sources'}

            if target_password:
                cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd] + sources + [f'{target_user}@{target_server}:{rsync_target_path}/']
            else:
                cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd] + sources + [f'{target_user}@{target_server}:{rsync_target_path}/']

            part_id = f"rsync_{uuid.uuid4().hex}"
            return_code = _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id)
            if return_code != 0:
                return {'success': False, 'message': f'rsync exit {return_code}'}

        elif transfer_mode == 'remote_to_local':
            source_user = SERVERS[source_server]['user']
            source_password = SERVERS[source_server].get('password')

            ssh_cmd = RSYNC_SSH_CMD
            source_port = SERVERS[source_server].get('port', 22)
            if source_port != 22:
                ssh_cmd = f"{ssh_cmd} -p {source_port}"

            sources = []
            for f in source_files:
                src_path = _normalize_batch_path(f.get('path', ''))
                if not src_path:
                    continue
                if source_is_windows:
                    src_path = convert_windows_path_to_cygwin(src_path)
                sources.append(f'{source_user}@{source_server}:{src_path}')

            if not sources:
                return {'success': False, 'message': 'empty sources'}

            if source_password:
                cmd = ['sshpass', '-p', source_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd] + sources + [f'{target_path}/']
            else:
                cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd] + sources + [f'{target_path}/']

            part_id = f"rsync_{uuid.uuid4().hex}"
            return_code = _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id)
            if return_code != 0:
                return {'success': False, 'message': f'rsync exit {return_code}'}

        elif transfer_mode == 'remote_to_remote':
            target_user = SERVERS[target_server]['user']
            target_password = SERVERS[target_server].get('password')
            source_user = SERVERS[source_server]['user']
            source_password = SERVERS[source_server].get('password')

            if source_is_windows and not target_is_windows:
                exec_server = target_server
                sshpass_cmd = "sshpass"

                ssh_to_source = RSYNC_SSH_CMD
                source_port = SERVERS[source_server].get('port', 22)
                if source_port != 22:
                    ssh_to_source = f"{ssh_to_source} -p {source_port}"

                sources = []
                for f in source_files:
                    src_path = _normalize_batch_path(f.get('path', ''))
                    if not src_path:
                        continue
                    src_path = convert_windows_path_to_cygwin(src_path)
                    sources.append(f'{source_user}@{source_server}:{src_path}')

                if not sources:
                    return {'success': False, 'message': 'empty sources'}

                sources_arg = ' '.join([shlex.quote(s) for s in sources])
                target_dest = shlex.quote(f'{target_path}/')
                if source_password:
                    remote_cmd = f"{sshpass_cmd} -p {shlex.quote(source_password)} rsync {rsync_opts_str} -e {shlex.quote(ssh_to_source)} {sources_arg} {target_dest}"
                else:
                    remote_cmd = f"rsync {rsync_opts_str} -e {shlex.quote(ssh_to_source)} {sources_arg} {target_dest}"

                ssh = ssh_manager.get_connection(exec_server)
                if not ssh:
                    raise Exception(f"æ— æ³•è¿æ¥åˆ°ç›®æ ‡æœåŠ¡å™¨ {exec_server}")
                part_id = f"rsync_{uuid.uuid4().hex}"
                exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
                if exit_status != 0:
                    return {'success': False, 'message': f'rsync exit {exit_status}: {error}'}
            else:
                exec_server = source_server
                sshpass_cmd = "sshpass"

                rsync_target_path = target_path
                if target_is_windows:
                    normalized_target = normalize_windows_path_for_transfer(target_path)
                    rsync_target_path = convert_windows_path_to_cygwin(normalized_target)

                ssh_to_target = RSYNC_SSH_CMD
                target_port = SERVERS[target_server].get('port', 22)
                if target_port != 22:
                    ssh_to_target = f"{ssh_to_target} -p {target_port}"

                sources = []
                for f in source_files:
                    src_path = _normalize_batch_path(f.get('path', ''))
                    if not src_path:
                        continue
                    if source_is_windows:
                        src_path = convert_windows_path_to_cygwin(src_path)
                    sources.append(src_path)

                if not sources:
                    return {'success': False, 'message': 'empty sources'}

                sources_arg = ' '.join([shlex.quote(s) for s in sources])
                dest = shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/')
                if target_password:
                    remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {rsync_opts_str} -e {shlex.quote(ssh_to_target)} {sources_arg} {dest}"
                else:
                    remote_cmd = f"rsync {rsync_opts_str} -e {shlex.quote(ssh_to_target)} {sources_arg} {dest}"

                ssh = ssh_manager.get_connection(exec_server)
                if not ssh:
                    raise Exception(f"æ— æ³•è¿æ¥åˆ°æºæœåŠ¡å™¨ {exec_server}")
                part_id = f"rsync_{uuid.uuid4().hex}"
                exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
                if exit_status != 0:
                    return {'success': False, 'message': f'rsync exit {exit_status}: {error}'}
        else:
            return {'success': False, 'message': 'unsupported mode'}

        if mode == 'move':
            paths = [_normalize_batch_path(f.get('path', '')) for f in source_files]
            paths = [p for p in paths if p]
            deleted_ok = _delete_source_paths_batch(source_server, paths)
            if not deleted_ok:
                emit_transfer_log(transfer_id, 'âš ï¸ å‰ªåˆ‡æ¨¡å¼ï¼šæºæ–‡ä»¶åˆ é™¤å­˜åœ¨å¤±è´¥é¡¹')

        return {'success': True, 'completed': len(source_files), 'failed': 0}

    except Exception as e:
        return {'success': False, 'message': str(e)}

def start_instant_parallel_transfer(transfer_id, source_server, source_files, target_server, target_path, mode="copy", fast_ssh=True, parallel_enabled=True):
    """Start instant parallel transfer tasks without pre-analysis."""
    def _log_transfer_summary(status: str, total_time: str = "", error: str = ""):
        meta = active_transfers.get(transfer_id, {})
        client_ip = meta.get('client_ip', 'æœªçŸ¥')
        src_server = meta.get('source_server', source_server)
        tgt_server = meta.get('target_server', target_server)
        target_base = meta.get('target_path', target_path)
        files = meta.get('source_files', source_files)
        if isinstance(files, list):
            file_names = ','.join([f.get('name', '') for f in files if isinstance(f, dict)])
            source_paths = ';'.join([f.get('path', '') for f in files if isinstance(f, dict)])
        else:
            file_names = ''
            source_paths = ''

        append_transfer_log_record(
            source_ip=src_server,
            target_ip=tgt_server,
            source_path=source_paths or target_base,
            target_full_path=target_base,
            duration_sec=_hhmmss_to_seconds(total_time),
            status=status,
            error=error,
            client_ip=client_ip,
            mode=meta.get('mode', mode),
            file_name=file_names or (files[0].get('name', '') if isinstance(files, list) and files else ''),
            action='transfer'
        )

    def transfer_worker():
        try:
            total_files = len(source_files)


            if (is_windows_server(source_server) or is_windows_server(target_server)):
                speed_simulator.init_transfer_speed(transfer_id, 50.0, 55.0)
            else:
                speed_simulator.init_transfer_speed(transfer_id)


            start_speed_update_timer(transfer_id, source_server, target_server)


            progress_manager.init_transfer(transfer_id, total_files)


            if not PERFORMANCE_CONFIG.get('reduce_websocket_traffic', True):
                emit_transfer_log(transfer_id, f'ğŸš€ ç«‹å³å¼€å§‹ä¼ è¾“ {total_files} ä¸ªé¡¹ç›®...')


            if not parallel_enabled or total_files == 1:

                time_tracker.start_transfer(transfer_id)

                return start_sequential_transfer(transfer_id, source_server, source_files, target_server, target_path, mode, fast_ssh)


            time_tracker.start_transfer(transfer_id)


            if PARALLEL_TRANSFER_CONFIG.get('enable_batch_transfer', True):
                batch_result = transfer_batch_instant(
                    transfer_id, source_server, source_files, target_server, target_path, mode, fast_ssh
                )
                if batch_result and batch_result.get('success'):
                    total_time = time_tracker.end_transfer(transfer_id)
                    completed_count = batch_result.get('completed', total_files)

                    _clear_transfer_listing_cache(source_server, target_server, source_files, target_path, mode)

                    emit_transfer_bytes_snapshot(transfer_id)
                    socketio.emit('transfer_complete', {
                        'transfer_id': transfer_id,
                        'status': 'success',
                        'message': f'æˆåŠŸä¼ è¾“ {completed_count} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹',
                        'total_time': total_time
                    })
                    _log_transfer_summary('success', total_time)
                    return
                elif batch_result and batch_result.get('message'):
                    print(f"[INFO] æ‰¹é‡ä¼ è¾“æœªå¯ç”¨æˆ–å¤±è´¥ï¼Œå›é€€å¹¶è¡Œæ¨¡å¼: {batch_result.get('message')}")


            max_workers = min(PARALLEL_TRANSFER_CONFIG['max_workers'], total_files)

            emit_transfer_log(transfer_id, f'âš¡ å¯åŠ¨ {max_workers} ä¸ªå¹¶è¡Œä¼ è¾“çº¿ç¨‹...')

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []


                for file_info in source_files:
                    future = executor.submit(
                        transfer_single_file_instant,
                        transfer_id, source_server, file_info, target_server, target_path, mode, fast_ssh
                    )
                    futures.append(future)


                completed_count = 0
                failed_count = 0

                for future in concurrent.futures.as_completed(futures):

                    if transfer_id not in active_transfers:

                        for f in futures:
                            f.cancel()
                        return

                    try:
                        result = future.result()

                        print(f"[DEBUG] ä¼ è¾“ä»»åŠ¡è¿”å›å€¼: {result}, ç±»å‹: {type(result)}")



                        is_success = False
                        if result is not None:
                            if isinstance(result, dict):
                                is_success = result.get('success', False)
                                print(f"[DEBUG] å­—å…¸è¿”å›å€¼ï¼Œsuccess={is_success}")
                            else:

                                print(f"[WARNING] ä¼ è¾“å‡½æ•°è¿”å›äº†éå­—å…¸å€¼: {result}, ç±»å‹: {type(result)}")

                                is_success = bool(result)
                        else:
                            print(f"[WARNING] ä¼ è¾“å‡½æ•°è¿”å›äº†None")

                        if is_success:
                            completed_count += 1
                            print(f"[DEBUG] ä¼ è¾“æˆåŠŸï¼Œå·²å®Œæˆ: {completed_count}/{total_files}")
                        else:
                            failed_count += 1
                            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯') if isinstance(result, dict) else str(result)
                            print(f"[DEBUG] ä¼ è¾“å¤±è´¥ï¼Œå¤±è´¥æ•°: {failed_count}, åŸå› : {error_msg}")



                    except Exception as e:

                        failed_count += 1
                        print(f"[ERROR] ä¼ è¾“ä»»åŠ¡å¼‚å¸¸: {str(e)}, ç±»å‹: {type(e).__name__}")
                        import traceback
                        print(f"[ERROR] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                        emit_transfer_log(transfer_id, f'âŒ ä¼ è¾“ä»»åŠ¡å¤±è´¥: {str(e)}')



            print(f"[DEBUG] ä¼ è¾“å®Œæˆç»Ÿè®¡ - æˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}, æ€»æ•°: {total_files}")


            processed_count = completed_count + failed_count
            if processed_count != total_files:
                print(f"[WARNING] ä»»åŠ¡å¤„ç†æ•°é‡ä¸åŒ¹é…ï¼å·²å¤„ç†: {processed_count}, æ€»æ•°: {total_files}")

                failed_count += (total_files - processed_count)
                print(f"[WARNING] è°ƒæ•´åå¤±è´¥æ•°: {failed_count}")

            if failed_count > 0:

                total_time = time_tracker.end_transfer(transfer_id)

                _clear_transfer_listing_cache(source_server, target_server, source_files, target_path, mode)

                print(f"[DEBUG] å‘é€éƒ¨åˆ†æˆåŠŸäº‹ä»¶: transfer_id={transfer_id}, status=partial_success")
                emit_transfer_bytes_snapshot(transfer_id)
                socketio.emit('transfer_complete', {
                    'transfer_id': transfer_id,
                    'status': 'partial_success',
                    'message': f'ä¼ è¾“å®Œæˆï¼ŒæˆåŠŸ: {completed_count}, å¤±è´¥: {failed_count}',
                    'total_time': total_time
                })
            else:
                # Stop transfer timing.
                total_time = time_tracker.end_transfer(transfer_id)

                _clear_transfer_listing_cache(source_server, target_server, source_files, target_path, mode)


                print(f"[æ€§èƒ½ç›‘æ§] ä¼ è¾“ID: {transfer_id}")
                print(f"[æ€§èƒ½ç›‘æ§] æ–‡ä»¶æ•°é‡: {completed_count}")
                print(f"[æ€§èƒ½ç›‘æ§] ä¼ è¾“æ—¶é—´: {total_time}")

                print(f"[æ€§èƒ½ç›‘æ§] é€Ÿåº¦æ›´æ–°é—´éš”: {PERFORMANCE_CONFIG['speed_update_interval']}ç§’")

                print(f"[DEBUG] å‘é€æˆåŠŸäº‹ä»¶: transfer_id={transfer_id}, status=success")
                emit_transfer_bytes_snapshot(transfer_id)
                socketio.emit('transfer_complete', {
                    'transfer_id': transfer_id,
                    'status': 'success',
                    'message': f'æˆåŠŸä¼ è¾“ {completed_count} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹',
                    'total_time': total_time
                })
                _log_transfer_summary('success', total_time)

        except Exception as e:

            total_time = time_tracker.end_transfer(transfer_id)


            print(f"[DEBUG] ä¼ è¾“å¼‚å¸¸: {str(e)}")
            print(f"[DEBUG] å‘é€é”™è¯¯äº‹ä»¶: transfer_id={transfer_id}, status=error")

            emit_transfer_bytes_snapshot(transfer_id)
            socketio.emit('transfer_complete', {
                'transfer_id': transfer_id,
                'status': 'error',
                'message': str(e),
                'total_time': total_time
            })
            try:
                _log_transfer_summary('failure', total_time, str(e))
            except Exception:
                pass
        finally:

            if transfer_id in active_transfers:
                del active_transfers[transfer_id]
            with TRANSFER_PROCESS_LOCK:
                transfer_processes.pop(transfer_id, None)
            progress_manager.cleanup_transfer(transfer_id)
            speed_simulator.cleanup_transfer(transfer_id)
            cleanup_transfer_bytes(transfer_id)


    thread = threading.Thread(target=transfer_worker)
    thread.daemon = True
    thread.start()

def transfer_single_file_instant(transfer_id, source_server, file_info, target_server, target_path, mode="copy", fast_ssh=True):
    """Instantly transfer a file or directory without pre-analysis."""
    try:
        transfer_meta = active_transfers.get(transfer_id, {})
        _client_ip_for_log = transfer_meta.get('client_ip', 'æœªçŸ¥')
        _mode_for_log = transfer_meta.get('mode', mode)

        source_path = file_info['path']
        file_name = file_info['name']
        is_directory = file_info['is_directory']

        _file_transfer_start_ts = time.time()
        _log_target_full_path = _join_target_full_path_for_log(target_server, target_path, file_name)
        _log_source_ip = _normalize_ip_for_log(source_server)
        _log_target_ip = _normalize_ip_for_log(target_server)


        emit_transfer_log(transfer_id, f'ğŸš€ å¼€å§‹ä¼ è¾“ {file_name}...')


        if transfer_id not in active_transfers:
            return {'success': False, 'message': 'ä¼ è¾“è¢«å–æ¶ˆ'}


        transfer_mode = determine_transfer_mode(source_server, target_server)

        print(f"ğŸ”„ ä¼ è¾“æ¨¡å¼: {transfer_mode} ({source_server} â†’ {target_server})")


        emit_transfer_log(transfer_id, f'ğŸ”„ ä¼ è¾“æ¨¡å¼: {transfer_mode} ({source_server} â†’ {target_server})')

        if transfer_mode == 'local_to_remote':

            print(f"ğŸ“ è°ƒç”¨å‡½æ•°: transfer_file_via_local_rsync_instant")
            success = transfer_file_via_local_rsync_instant(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode)
            if not success:
                raise Exception("æœ¬åœ°åˆ°è¿œç¨‹ä¼ è¾“å¤±è´¥")
        elif transfer_mode == 'remote_to_local':

            print(f"ğŸ“ è°ƒç”¨å‡½æ•°: transfer_file_via_remote_to_local_rsync_instant")
            success = transfer_file_via_remote_to_local_rsync_instant(source_server, source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode)
            if not success:
                raise Exception("è¿œç¨‹åˆ°æœ¬åœ°ä¼ è¾“å¤±è´¥")
        elif transfer_mode == 'remote_to_remote':

            print(f"ğŸ“ è°ƒç”¨å‡½æ•°: transfer_file_via_remote_rsync_instant")
            success = transfer_file_via_remote_rsync_instant(source_server, source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode)
            if not success:
                raise Exception("è¿œç¨‹åˆ°è¿œç¨‹ä¼ è¾“å¤±è´¥")
        else:

            print(f"ğŸ“ è°ƒç”¨å‡½æ•°: transfer_file_via_local_to_local_instant")
            print(f"[DEBUG] å‚æ•°: source_path={source_path}, target_path={target_path}, file_name={file_name}, is_directory={is_directory}, mode={mode}")

            operation = "å‰ªåˆ‡" if mode == "move" else "å¤åˆ¶"
            cmd_name = "mv" if mode == "move" else "cp"
            emit_transfer_log(transfer_id, f'ğŸ”„ ä¼ è¾“æ¨¡å¼: local_to_local (æœ¬åœ°åˆ°æœ¬åœ°{operation}ï¼Œä½¿ç”¨{cmd_name}å‘½ä»¤)')

            success = transfer_file_via_local_to_local_instant(source_path, target_path, file_name, is_directory, transfer_id, mode)
            print(f"[DEBUG] transfer_file_via_local_to_local_instantè¿”å›å€¼: {success}, ç±»å‹: {type(success)}")
            if not success:
                raise Exception(f"æœ¬åœ°åˆ°æœ¬åœ°{operation}å¤±è´¥")
            print(f"[DEBUG] æœ¬åœ°åˆ°æœ¬åœ°{operation}æˆåŠŸï¼Œå‡†å¤‡è¿”å›å­—å…¸")



        need_delete_source = mode == "move" and not (transfer_mode == 'local_to_local' or (transfer_mode == 'remote_to_remote' and source_server == target_server))

        if need_delete_source:
            try:
                if is_local_server(source_server):

                    import shutil
                    if is_directory:
                        shutil.rmtree(source_path)
                    else:
                        os.remove(source_path)
                    emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ å·²åˆ é™¤æºæ–‡ä»¶: {file_name}')
                else:

                    is_windows = is_windows_server(source_server)
                    if is_windows:

                        win_path = normalize_windows_path_for_cmd(source_path)
                        ps_path = win_path.replace("'", "''")
                        delete_cmd = (
                            "powershell -NoProfile -Command "
                            f"\"Remove-Item -LiteralPath '{ps_path}' -Force -Recurse -ErrorAction SilentlyContinue; "
                            f"if (Test-Path -LiteralPath '{ps_path}') {{ exit 1 }}\""
                        )
                        emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ æ‰§è¡ŒWindowsåˆ é™¤å‘½ä»¤: {delete_cmd}')
                    else:

                        delete_cmd = f"rm -rf {shlex.quote(source_path)}"
                        emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ æ‰§è¡ŒLinuxåˆ é™¤å‘½ä»¤: {delete_cmd}')

                    stdout, stderr, exit_code = ssh_manager.execute_command(source_server, delete_cmd)
                    if exit_code == 0:
                        emit_transfer_log(transfer_id, f'âœ… å·²åˆ é™¤æºæ–‡ä»¶: {file_name}')
                    else:
                        emit_transfer_log(transfer_id, f'âŒ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {stderr}')
            except Exception as e:
                emit_transfer_log(transfer_id, f'âŒ åˆ é™¤æºæ–‡ä»¶å¼‚å¸¸: {str(e)}')

        emit_transfer_log(transfer_id, f'âœ… {file_name} ä¼ è¾“å®Œæˆ')


        try:
            append_transfer_log_record(
                source_ip=_log_source_ip,
                target_ip=_log_target_ip,
                source_path=source_path,
                target_full_path=_log_target_full_path,
                duration_sec=(time.time() - _file_transfer_start_ts),
                status='success',
                error="",
                client_ip=_client_ip_for_log,
                mode=_mode_for_log,
                file_name=file_name
            )
        except Exception:
            pass

        return {'success': True, 'message': f'{file_name} ä¼ è¾“å®Œæˆ'}

    except Exception as e:

        try:
            append_transfer_log_record(
                source_ip=_log_source_ip if '_log_source_ip' in locals() else source_server,
                target_ip=_log_target_ip if '_log_target_ip' in locals() else target_server,
                source_path=source_path if 'source_path' in locals() else file_info.get('path', ''),
                target_full_path=_log_target_full_path if '_log_target_full_path' in locals() else _join_target_full_path_for_log(target_server, target_path, file_info.get('name', '')),
                duration_sec=(time.time() - _file_transfer_start_ts) if '_file_transfer_start_ts' in locals() else 0.0,
                status='failure',
                error=str(e),
                client_ip=_client_ip_for_log,
                mode=_mode_for_log,
                file_name=file_info.get('name', '')
            )
        except Exception:
            pass


        try:
            failed_source_path = source_path if 'source_path' in locals() else file_info.get('path', '')
        except Exception:
            failed_source_path = ''
        try:
            failed_target_full = _log_target_full_path if '_log_target_full_path' in locals() else _join_target_full_path_for_log(target_server, target_path, file_info.get('name', ''))
        except Exception:
            failed_target_full = ''
        failed_name = ''
        try:
            if isinstance(file_info, dict):
                failed_name = file_info.get('name', '')
        except Exception:
            failed_name = ''

        emit_transfer_log(
            transfer_id,
            f'âŒ ä¼ è¾“å¤±è´¥: {failed_name or "[æœªçŸ¥åç§°]"} | æº: {source_server}:{failed_source_path} -> ç›®æ ‡: {target_server}:{failed_target_full} | é”™è¯¯: {str(e)}'
        )
        return {'success': False, 'message': str(e)}

def transfer_file_via_local_rsync_instant(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode='copy'):
    """Instant local rsync transfer with folder-level parallelism and NAS support."""





    enable_folder_parallel = PARALLEL_TRANSFER_CONFIG.get('enable_folder_parallel', False)
    folder_parallel_threshold = PARALLEL_TRANSFER_CONFIG.get('folder_parallel_threshold', 1000)

    if is_directory and enable_folder_parallel:

        try:
            file_count = sum(len(files) for _, _, files in os.walk(source_path))
            if file_count > folder_parallel_threshold:

                return transfer_directory_parallel(source_path, target_server, target_path, file_name, transfer_id, fast_ssh, mode)
        except:
            pass


    return transfer_single_rsync(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode)

def transfer_single_rsync(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode='copy'):
    """Single rsync transfer implementation."""



    target_user = SERVERS[target_server]['user']
    target_password = SERVERS[target_server].get('password')


    target_is_windows = is_windows_server(target_server)


    rsync_opts = [
        '-a',
        '--inplace',
        '--whole-file',
        '--no-compress',
        '--numeric-ids',
        '--timeout=600',
        '-s',
        '--no-perms',
        '--no-owner',
        '--no-group',
        '--omit-dir-times',
    ]

    if target_is_windows:
        rsync_opts.append('--iconv=UTF-8,UTF-8')
    _append_rsync_progress_opts(rsync_opts)








    rsync_target_path = target_path
    if target_is_windows:
        normalized_target = normalize_windows_path_for_transfer(target_path)
        rsync_target_path = convert_windows_path_to_cygwin(normalized_target)
        print(f"ğŸ”„ Windowsç›®æ ‡è·¯å¾„è½¬æ¢: {target_path} -> {rsync_target_path}")


    ssh_cmd = RSYNC_SSH_CMD


    target_port = SERVERS[target_server].get('port', 22)
    if target_port != 22:
        ssh_cmd = f"{ssh_cmd} -p {target_port}"

    if is_directory:
        if target_password:
            cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_path}/', f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/']
        else:
            cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_path}/', f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/']
    else:
        if target_password:
            cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd, source_path, f'{target_user}@{target_server}:{rsync_target_path}/']
        else:
            cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd, source_path, f'{target_user}@{target_server}:{rsync_target_path}/']


    part_id = f"rsync_{uuid.uuid4().hex}"
    return_code = _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id)
    if return_code != 0:
        raise Exception(f"rsyncä¼ è¾“å¤±è´¥ï¼Œé€€å‡ºç : {return_code}")


    return True

def transfer_directory_parallel(source_path, target_server, target_path, file_name, transfer_id, fast_ssh, mode='copy'):
    """In-directory parallel transfer implementation."""
    target_user = SERVERS[target_server]['user']
    target_password = SERVERS[target_server].get('password')

    target_is_windows = is_windows_server(target_server)
    remote_target_root = target_path
    if target_is_windows:
        normalized = normalize_windows_path_for_transfer(target_path)
        remote_target_root = convert_windows_path_to_cygwin(normalized)

    emit_transfer_log(transfer_id, f'ğŸ“ å¯ç”¨ç›®å½•å†…éƒ¨å¹¶è¡Œä¼ è¾“: {file_name}')


    parallel_tasks = []

    try:

        items = os.listdir(source_path)
        subdirs = []
        files = []

        for item in items:
            item_path = os.path.join(source_path, item)
            if os.path.isdir(item_path):
                subdirs.append(item)
            else:
                files.append(item)


        for subdir in subdirs:
            parallel_tasks.append({
                'type': 'subdir',
                'source': os.path.join(source_path, subdir),
                'target_subpath': f'{file_name}/{subdir}',
                'name': subdir
            })


        if files:

            max_file_groups = 3
            group_size = max(1, len(files) // max_file_groups)

            for i in range(0, len(files), group_size):
                file_group = files[i:i + group_size]
                parallel_tasks.append({
                    'type': 'files',
                    'files': file_group,
                    'source_dir': source_path,
                    'target_subpath': file_name,
                    'name': f'æ–‡ä»¶ç»„{i//group_size + 1}'
                })

        emit_transfer_log(transfer_id, f'ğŸ“Š å¹¶è¡Œä»»åŠ¡: {len(subdirs)}ä¸ªå­ç›®å½• + {len(files)}ä¸ªæ–‡ä»¶ â†’ {len(parallel_tasks)}ä¸ªå¹¶è¡Œä»»åŠ¡')


        max_workers = min(4, len(parallel_tasks))

        def execute_parallel_task(task):
            """Execute a single parallel task."""

            rsync_opts = ['-a', '--inplace', '--whole-file', '--no-compress', '--numeric-ids', '--timeout=600', '--no-perms', '--no-owner', '--no-group', '--omit-dir-times']
            if target_is_windows:
                rsync_opts.append('--iconv=UTF-8,UTF-8')

            if task['type'] == 'subdir':

                if target_password:
                    cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + ['-e', RSYNC_SSH_CMD,
                        f"{task['source']}/", f"{target_user}@{target_server}:{remote_target_root}/{task['target_subpath']}/"
                    ]
                else:
                    cmd = ['rsync'] + rsync_opts + ['-e', RSYNC_SSH_CMD,
                        f"{task['source']}/", f"{target_user}@{target_server}:{remote_target_root}/{task['target_subpath']}/"
                    ]
            else:

                file_paths = [os.path.join(task['source_dir'], f) for f in task['files']]
                if target_password:
                    cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + ['-e', RSYNC_SSH_CMD] + file_paths + [
                        f"{target_user}@{target_server}:{remote_target_root}/{task['target_subpath']}/"
                    ]
                else:
                    cmd = ['rsync'] + rsync_opts + ['-e', RSYNC_SSH_CMD] + file_paths + [
                        f"{target_user}@{target_server}:{remote_target_root}/{task['target_subpath']}/"
                    ]

            try:
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
                if result.returncode == 0:
                    return {'success': True, 'task_name': task['name']}
                else:
                    return {'success': False, 'task_name': task['name'], 'error': result.stderr}
            except Exception as e:
                return {'success': False, 'task_name': task['name'], 'error': str(e)}


        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(execute_parallel_task, task) for task in parallel_tasks]


            completed_tasks = 0
            failed_tasks = 0

            for future in concurrent.futures.as_completed(futures):

                if transfer_id not in active_transfers:

                    for f in futures:
                        f.cancel()
                    raise Exception("ä¼ è¾“è¢«ç”¨æˆ·å–æ¶ˆ")

                result = future.result()
                if result['success']:
                    completed_tasks += 1
                    emit_transfer_log(transfer_id, f'âœ… å¹¶è¡Œä»»åŠ¡å®Œæˆ: {result["task_name"]}')
                else:
                    failed_tasks += 1
                    emit_transfer_log(transfer_id, f'âŒ å¹¶è¡Œä»»åŠ¡å¤±è´¥: {result["task_name"]} - {result.get("error", "æœªçŸ¥é”™è¯¯")}')

        if failed_tasks > 0:
            raise Exception(f"ç›®å½•å¹¶è¡Œä¼ è¾“éƒ¨åˆ†å¤±è´¥: {failed_tasks}/{len(parallel_tasks)} ä»»åŠ¡å¤±è´¥")

        emit_transfer_log(transfer_id, f'ğŸ‰ ç›®å½•å¹¶è¡Œä¼ è¾“å®Œæˆ: {completed_tasks}/{len(parallel_tasks)} ä»»åŠ¡æˆåŠŸ')

    except Exception as e:
        emit_transfer_log(transfer_id, f'âš ï¸ ç›®å½•å¹¶è¡Œä¼ è¾“å¤±è´¥ï¼Œå›é€€åˆ°å•rsync: {str(e)}')

        return transfer_single_rsync(source_path, target_server, target_path, file_name, True, transfer_id, fast_ssh, mode='copy')

def transfer_file_via_remote_to_local_rsync_instant(source_server, source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode='copy'):
    """Transfer from remote server to TurboFile host using rsync pull."""



    source_user = SERVERS[source_server]['user']
    source_password = SERVERS[source_server].get('password')


    source_is_windows = is_windows_server(source_server)


    rsync_opts = [
        '-a',
        '--inplace',
        '--whole-file',
        '--no-compress',
        '--numeric-ids',
        '--timeout=600',
        '-s',
        '--no-perms',
        '--no-owner',
        '--no-group',
        '--omit-dir-times',
    ]
    if source_is_windows:
        rsync_opts.append('--iconv=UTF-8,UTF-8')
    _append_rsync_progress_opts(rsync_opts)


    rsync_source_path = source_path
    if source_is_windows:
        rsync_source_path = convert_windows_path_to_cygwin(source_path)
        print(f"ğŸ”„ Windowsæºè·¯å¾„è½¬æ¢: {source_path} -> {rsync_source_path}")



    ssh_cmd = RSYNC_SSH_CMD
    source_port = SERVERS[source_server].get('port', 22)
    if source_port != 22:
        ssh_cmd = f"{ssh_cmd} -p {source_port}"

    if is_directory:
        if source_password:
            cmd = ['sshpass', '-p', source_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_user}@{source_server}:{rsync_source_path}/', f'{target_path}/{file_name}/']
        else:
            cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_user}@{source_server}:{rsync_source_path}/', f'{target_path}/{file_name}/']
    else:
        if source_password:
            cmd = ['sshpass', '-p', source_password, 'rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_user}@{source_server}:{rsync_source_path}', f'{target_path}/']
        else:
            cmd = ['rsync'] + rsync_opts + ['-e', ssh_cmd, f'{source_user}@{source_server}:{rsync_source_path}', f'{target_path}/']


    part_id = f"rsync_{uuid.uuid4().hex}"
    return_code = _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id)
    if return_code != 0:
        raise Exception(f"rsyncä¼ è¾“å¤±è´¥ï¼Œé€€å‡ºç : {return_code}")


    return True

def transfer_file_via_local_to_local_instant(source_path, target_path, file_name, is_directory, transfer_id, mode='copy'):
    """Local-to-local transfer using cp (copy) or mv (move).

    Args:
        source_path: source path
        target_path: target directory path
        file_name: file name
        is_directory: is a directory
        transfer_id: transfer ID
        mode: transfer mode, 'copy' or 'move'
    """
    import subprocess

    try:
        dest_path = os.path.join(target_path, file_name)

        if mode == 'move':

            print(f"[DEBUG] æœ¬åœ°å‰ªåˆ‡: {source_path} -> {dest_path}")

            emit_transfer_log(transfer_id, f'âœ‚ï¸ æœ¬åœ°åˆ°æœ¬åœ°å‰ªåˆ‡ï¼Œä½¿ç”¨ mv å‘½ä»¤')


            mv_cmd = ['mv', '-f', source_path, target_path + '/']

            cmd_str = ' '.join(mv_cmd)
            print(f"[DEBUG] æ‰§è¡Œå‘½ä»¤: {cmd_str}")

            emit_transfer_log(transfer_id, f'ğŸ“ æ‰§è¡Œå‘½ä»¤: {cmd_str}')

            result = subprocess.run(mv_cmd, capture_output=True, text=True, timeout=300)

            if result.returncode != 0:
                error_msg = result.stderr.strip() if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"[ERROR] mvå¤±è´¥: returncode={result.returncode}, stderr={error_msg}")
                raise Exception(f"æœ¬åœ°å‰ªåˆ‡å¤±è´¥: {error_msg}")

            print(f"[DEBUG] mvæˆåŠŸ: {file_name}")

            emit_transfer_log(transfer_id, f'âœ… æœ¬åœ°å‰ªåˆ‡å®Œæˆ: {file_name}')
        else:

            if is_directory:

                print(f"[DEBUG] æœ¬åœ°ç›®å½•å¤åˆ¶: {source_path} -> {dest_path}")

                emit_transfer_log(transfer_id, f'ğŸ“ æœ¬åœ°åˆ°æœ¬åœ°å¤åˆ¶ï¼Œä½¿ç”¨ cp -r å‘½ä»¤')


                cp_cmd = ['cp', '-r', source_path, target_path + '/']

                cmd_str = ' '.join(cp_cmd)
                print(f"[DEBUG] æ‰§è¡Œå‘½ä»¤: {cmd_str}")

                emit_transfer_log(transfer_id, f'ğŸ“ æ‰§è¡Œå‘½ä»¤: {cmd_str}')

                result = subprocess.run(cp_cmd, capture_output=True, text=True, timeout=300)

                if result.returncode != 0:
                    error_msg = result.stderr.strip() if result.stderr else "æœªçŸ¥é”™è¯¯"
                    print(f"[ERROR] cp -rå¤±è´¥: returncode={result.returncode}, stderr={error_msg}")
                    raise Exception(f"æœ¬åœ°ç›®å½•å¤åˆ¶å¤±è´¥: {error_msg}")

                print(f"[DEBUG] cp -ræˆåŠŸ: {file_name}")
            else:

                print(f"[DEBUG] æœ¬åœ°æ–‡ä»¶å¤åˆ¶: {source_path} -> {dest_path}")


                cp_cmd = ['cp', '-f', source_path, dest_path]

                print(f"[DEBUG] æ‰§è¡Œå‘½ä»¤: {' '.join(cp_cmd)}")
                result = subprocess.run(cp_cmd, capture_output=True, text=True, timeout=60)

                if result.returncode != 0:
                    error_msg = result.stderr.strip() if result.stderr else "æœªçŸ¥é”™è¯¯"
                    print(f"[ERROR] cpå¤±è´¥: returncode={result.returncode}, stderr={error_msg}")
                    raise Exception(f"æœ¬åœ°æ–‡ä»¶å¤åˆ¶å¤±è´¥: {error_msg}")

                print(f"[DEBUG] cpæˆåŠŸ: {file_name}")

            emit_transfer_log(transfer_id, f'âœ… æœ¬åœ°å¤åˆ¶å®Œæˆ: {file_name}')

        print(f"[DEBUG] transfer_file_via_local_to_local_instantè¿”å›True")
        return True

    except subprocess.TimeoutExpired:
        error_msg = f"æœ¬åœ°æ“ä½œè¶…æ—¶: {file_name}"
        print(f"[ERROR] {error_msg}")
        raise Exception(error_msg)
    except Exception as e:
        error_msg = f"æœ¬åœ°æ“ä½œå¤±è´¥: {str(e)}"
        print(f"[ERROR] {error_msg}")
        raise Exception(error_msg)

def transfer_file_via_remote_rsync_instant(source_server, source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode='copy'):
    """Instant remote rsync transfer without progress monitoring, tuned for speed.

    Args:
        mode: transfer mode, 'copy' or 'move'
    """
    print(f"ğŸ” è¿œç¨‹ä¼ è¾“æ£€æŸ¥: æº={source_server}, ç›®æ ‡={target_server}, æ¨¡å¼={mode}")


    if source_server == target_server:
        print(f"ğŸ” æ£€æµ‹åˆ°æºå’Œç›®æ ‡æ˜¯åŒä¸€å°æœåŠ¡å™¨: {source_server}")


        is_windows = is_windows_server(source_server)

        dest_path = os.path.join(target_path, file_name)

        if mode == 'move':

            if is_windows:

                print(f"ğŸªŸ WindowsæœåŠ¡å™¨ä½¿ç”¨moveå‘½ä»¤è¿›è¡Œæœ¬åœ°å‰ªåˆ‡")
                emit_transfer_log(transfer_id, f'âœ‚ï¸ åœ¨WindowsæœåŠ¡å™¨ä¸Šä½¿ç”¨moveå‰ªåˆ‡: {file_name}')

                src_cmd_path = normalize_windows_path_for_cmd(source_path)
                dest_cmd_path = normalize_windows_path_for_cmd(dest_path)

                ps_src = src_cmd_path.replace("'", "''")
                ps_dst = dest_cmd_path.replace("'", "''")
                ps_script = (
                    "$ErrorActionPreference='Stop';"
                    f"$src='{ps_src}';$dst='{ps_dst}';"
                    "$same=[string]::Equals($src.TrimEnd('\\','/'),$dst.TrimEnd('\\','/'),"
                    "[System.StringComparison]::InvariantCultureIgnoreCase);"
                    "if($same){exit 0};"
                    "if(Test-Path -LiteralPath $dst){Remove-Item -LiteralPath $dst -Force -Recurse -ErrorAction SilentlyContinue};"
                    "Move-Item -LiteralPath $src -Destination $dst -Force -ErrorAction Stop"
                )
                remote_cmd = f'powershell -NoProfile -Command "{ps_script}"'
            else:

                print(f"ğŸ§ LinuxæœåŠ¡å™¨ä½¿ç”¨mvå‘½ä»¤è¿›è¡Œæœ¬åœ°å‰ªåˆ‡")
                emit_transfer_log(transfer_id, f'âœ‚ï¸ åœ¨LinuxæœåŠ¡å™¨ä¸Šä½¿ç”¨mvå‰ªåˆ‡: {file_name}')


                remote_cmd = f"mv -f {shlex.quote(source_path)} {shlex.quote(target_path + '/')}"

            print(f"[DEBUG] åŒæœåŠ¡å™¨å‰ªåˆ‡å‘½ä»¤: {remote_cmd}")
        else:

            if is_windows:
                print(f"ğŸªŸ WindowsæœåŠ¡å™¨ä½¿ç”¨copy/xcopyè¿›è¡Œæœ¬åœ°å¤åˆ¶")
                emit_transfer_log(transfer_id, f'ğŸ“ åœ¨WindowsæœåŠ¡å™¨ä¸Šä½¿ç”¨copy/xcopyå¤åˆ¶: {file_name}')

                src_cmd_path = normalize_windows_path_for_cmd(source_path)
                dest_cmd_path = normalize_windows_path_for_cmd(dest_path)
                if is_directory:

                    remote_cmd = f'xcopy "{src_cmd_path}" "{dest_cmd_path}" /E /I /Y /Q'
                else:
                    remote_cmd = f'copy /Y "{src_cmd_path}" "{dest_cmd_path}"'
            else:

                print(f"ğŸ§ LinuxæœåŠ¡å™¨ä½¿ç”¨cpå‘½ä»¤è¿›è¡Œæœ¬åœ°å¤åˆ¶")
                emit_transfer_log(transfer_id, f'ğŸ“ åœ¨LinuxæœåŠ¡å™¨ä¸Šä½¿ç”¨cpå¤åˆ¶: {file_name}')

                if is_directory:

                    remote_cmd = f"cp -r {shlex.quote(source_path)} {shlex.quote(target_path + '/')}"
                else:

                    remote_cmd = f"cp -f {shlex.quote(source_path)} {shlex.quote(dest_path)}"

            print(f"[DEBUG] åŒæœåŠ¡å™¨å¤åˆ¶å‘½ä»¤: {remote_cmd}")


        try:
            output, error, exit_code = ssh_manager.execute_command(source_server, remote_cmd)


            if mode == 'move':

                if is_windows:

                    if exit_code != 0 or (error and 'cannot find' in error.lower()):
                        err_msg = error or f"exit_code={exit_code}"
                        print(f"[ERROR] moveå¤±è´¥: {err_msg}")
                        raise Exception(f"moveå‰ªåˆ‡å¤±è´¥: {err_msg}")
                    else:
                        print(f"[DEBUG] moveæˆåŠŸ")
                else:

                    if exit_code != 0:
                        err_msg = error or f"exit_code={exit_code}"
                        print(f"[ERROR] mvå¤±è´¥: {err_msg}")
                        raise Exception(f"mvå‰ªåˆ‡å¤±è´¥: {err_msg}")
                    else:
                        print(f"[DEBUG] mvæˆåŠŸ")

                emit_transfer_log(transfer_id, f'âœ… åŒæœåŠ¡å™¨å‰ªåˆ‡å®Œæˆ: {file_name}')
            else:

                if is_windows:
                    if exit_code != 0:
                        err_msg = error or output or f"exit_code={exit_code}"
                        print(f"[ERROR] copy/xcopyå¤±è´¥: {err_msg}")
                        raise Exception(f"copy/xcopyå¤åˆ¶å¤±è´¥: {err_msg}")
                    else:
                        print(f"[DEBUG] copy/xcopyæˆåŠŸ")
                else:

                    if exit_code != 0:
                        err_msg = error or f"exit_code={exit_code}"
                        print(f"[ERROR] cpå¤±è´¥: {err_msg}")
                        raise Exception(f"cpå¤åˆ¶å¤±è´¥: {err_msg}")
                    else:
                        print(f"[DEBUG] cpæˆåŠŸ")

                emit_transfer_log(transfer_id, f'âœ… åŒæœåŠ¡å™¨å¤åˆ¶å®Œæˆ: {file_name}')

            return True

        except Exception as e:
            operation = "å‰ªåˆ‡" if mode == 'move' else "å¤åˆ¶"
            error_msg = f"åŒæœåŠ¡å™¨{operation}å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            emit_transfer_log(transfer_id, f'âŒ {error_msg}')
            raise Exception(error_msg)



    print(f"ğŸ”„ ä½¿ç”¨rsyncä¼ è¾“æ–¹æ¡ˆ")


    source_is_windows = is_windows_server(source_server)
    target_is_windows = is_windows_server(target_server)

    print(f"ğŸ” Windowsæ£€æµ‹ç»“æœ: æºæ˜¯Windows={source_is_windows}, ç›®æ ‡æ˜¯Windows={target_is_windows}")

    target_user = SERVERS[target_server]['user']
    target_password = SERVERS[target_server].get('password')
    source_user = SERVERS[source_server]['user']
    source_password = SERVERS[source_server].get('password')


    rsync_base_opts = [
        "-a",
        "--inplace",
        "--whole-file",
        "--no-compress",
        "--numeric-ids",
        "--timeout=600",
        "-s",
        "--no-perms",
        "--no-owner",
        "--no-group",
        "--omit-dir-times",
    ]

    if source_is_windows or target_is_windows:
        rsync_base_opts.append("--iconv=UTF-8,UTF-8")
    _append_rsync_progress_opts(rsync_base_opts)


    if source_is_windows and not target_is_windows:
        emit_transfer_log(transfer_id, 'ğŸ” æ£€æµ‹åˆ°Windowsä½œä¸ºæºï¼Œåˆ‡æ¢ä¸ºåœ¨ç›®æ ‡Linuxä¸Šè¿è¡Œrsyncä»Windowsæ‹‰å–')

        rsync_source_path = convert_windows_path_to_cygwin(source_path)
        print(f"ğŸ”„ Windowsæºè·¯å¾„è½¬æ¢: {source_path} -> {rsync_source_path}")


        sshpass_cmd = "sshpass"


        ssh_to_source = RSYNC_SSH_CMD

        source_port = SERVERS[source_server].get('port', 22)
        if source_port != 22:
            ssh_to_source = f"{ssh_to_source} -p {source_port}"
        if is_directory:
            if source_password:
                remote_cmd = f"{sshpass_cmd} -p {shlex.quote(source_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}/')} {shlex.quote(f'{target_path}/{file_name}/')}"
            else:
                remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}/')} {shlex.quote(f'{target_path}/{file_name}/')}"
        else:
            if source_password:
                remote_cmd = f"{sshpass_cmd} -p {shlex.quote(source_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}')} {shlex.quote(f'{target_path}/')}"
            else:
                remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}')} {shlex.quote(f'{target_path}/')}"

        print(f"ğŸ”„ ç›®æ ‡æœåŠ¡å™¨æ‰§è¡Œçš„æ‹‰å–å‘½ä»¤: {remote_cmd}")


        ssh = ssh_manager.get_connection(target_server)
        if not ssh:
            raise Exception(f"æ— æ³•è¿æ¥åˆ°ç›®æ ‡æœåŠ¡å™¨ {target_server}")

        start_time = time.time()
        part_id = f"rsync_{uuid.uuid4().hex}"
        exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
        end_time = time.time()
        transfer_duration = end_time - start_time
        print(f"ğŸ“Š æ‹‰å–å®Œæˆ - è€—æ—¶: {transfer_duration:.2f}ç§’, çŠ¶æ€: {exit_status}")
        if error:
            print(f"âš ï¸ é”™è¯¯ä¿¡æ¯: {error}")

        emit_transfer_log(transfer_id, f'âœ… {file_name} ä¼ è¾“å®Œæˆ')
        if exit_status != 0:
            raise Exception(f"rsyncæ‹‰å–å¤±è´¥ï¼Œé€€å‡ºç : {exit_status}, é”™è¯¯: {error}")
        return True




    rsync_source_path = source_path
    if source_is_windows:
        rsync_source_path = convert_windows_path_to_cygwin(source_path)
        print(f"ğŸ”„ Windowsæºè·¯å¾„è½¬æ¢: {source_path} -> {rsync_source_path}")

    rsync_target_path = target_path
    if target_is_windows:
        rsync_target_path = convert_windows_path_to_cygwin(target_path)
        print(f"ğŸ”„ Windowsç›®æ ‡è·¯å¾„è½¬æ¢: {target_path} -> {rsync_target_path}")


    sshpass_cmd = "sshpass"



    ssh_to_target = RSYNC_SSH_CMD
    target_port = SERVERS[target_server].get('port', 22)
    if target_port != 22:
        ssh_to_target = f"{ssh_to_target} -p {target_port}"

    if is_directory:
        if target_password:
            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(f'{rsync_source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/')}"
        else:
            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(f'{rsync_source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/')}"
    else:
        if target_password:
            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(rsync_source_path)} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/')}"
        else:
            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(rsync_source_path)} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/')}"

    print(f"ğŸ”„ è¿œç¨‹rsyncå‘½ä»¤: {remote_cmd}")

    start_time = time.time()
    ssh = ssh_manager.get_connection(source_server)
    if not ssh:
        raise Exception(f"æ— æ³•è¿æ¥åˆ°æºæœåŠ¡å™¨ {source_server}")
    part_id = f"rsync_{uuid.uuid4().hex}"
    exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
    end_time = time.time()
    transfer_duration = end_time - start_time
    print(f"ğŸ“Š ä¼ è¾“å®Œæˆ - è€—æ—¶: {transfer_duration:.2f}ç§’")
    print(f"ğŸ“Š é€€å‡ºçŠ¶æ€: {exit_status}")
    if error:
        print(f"âš ï¸ é”™è¯¯ä¿¡æ¯: {error}")
    emit_transfer_log(transfer_id, f'âœ… {file_name} ä¼ è¾“å®Œæˆ')
    if exit_status != 0:
        raise Exception(f"rsyncä¼ è¾“å¤±è´¥ï¼Œé€€å‡ºç : {exit_status}, é”™è¯¯: {error}")
    return True

def transfer_file_batch(transfer_id, source_server, file_batch, target_server, target_path, mode="copy", fast_ssh=True):
    """Batch transfer small files."""
    completed = 0
    failed = 0

    for file_info in file_batch:
        try:

            if transfer_id not in active_transfers:
                break

            result = transfer_single_file(transfer_id, source_server, file_info, target_server, target_path, mode, fast_ssh)
            completed += result['completed_files']
            failed += result['failed_files']

        except Exception as e:
            failed += 1
            emit_transfer_log(transfer_id, f'âŒ æ‰¹é‡ä¼ è¾“å¤±è´¥: {str(e)}')

    return {'completed_files': completed, 'failed_files': failed}

def transfer_file_via_remote_rsync(source_server, source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, mode='copy'):
    """Transfer files via remote rsync."""



    target_user = SERVERS[target_server]['user']
    target_password = SERVERS[target_server].get('password')


    source_is_windows = is_windows_server(source_server)
    target_is_windows = is_windows_server(target_server)


    ssh_cmd = RSYNC_SSH_CMD


    target_port = SERVERS[target_server].get('port', 22)
    if target_port != 22:
        ssh_cmd = f"{ssh_cmd} -p {target_port}"
        print(f"ğŸ”§ ç›®æ ‡æœåŠ¡å™¨ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£: {target_port}")


    rsync_base_opts = [
        "-a",
        "--inplace",
        "--whole-file",
        "--no-compress",
        "--numeric-ids",
        "--timeout=600",
        "-s",
        "--no-perms",
        "--no-owner",
        "--no-group",
        "--omit-dir-times",
    ]
    if source_is_windows or target_is_windows:
        rsync_base_opts.append("--iconv=UTF-8,UTF-8")
    _append_rsync_progress_opts(rsync_base_opts)


    sshpass_cmd = "sshpass"


    if is_directory:
        if target_password:
            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_cmd)} {shlex.quote(f'{source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{target_path}/{file_name}/')}"
        else:
            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_cmd)} {shlex.quote(f'{source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{target_path}/{file_name}/')}"
    else:
        if target_password:
            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_cmd)} {shlex.quote(source_path)} {shlex.quote(f'{target_user}@{target_server}:{target_path}/')}"
        else:
            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_cmd)} {shlex.quote(source_path)} {shlex.quote(f'{target_user}@{target_server}:{target_path}/')}"


    ssh = ssh_manager.get_connection(source_server)
    if not ssh:
        raise Exception(f"æ— æ³•è¿æ¥åˆ°æºæœåŠ¡å™¨ {source_server}")

    start_time = time.time()


    part_id = f"rsync_{uuid.uuid4().hex}"
    exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
    if exit_status != 0:
        raise Exception(f"rsyncä¼ è¾“å¤±è´¥ (é€€å‡ºç : {exit_status}): {error}")

def start_sequential_transfer(transfer_id, source_server, source_files, target_server, target_path, mode="copy", fast_ssh=True):
    """Original sequential transfer logic (fallback)."""
    total_files = len(source_files)
    completed_files = 0




    if (is_windows_server(source_server) or is_windows_server(target_server)):
        speed_simulator.init_transfer_speed(transfer_id, 50.0, 55.0)
    else:
        speed_simulator.init_transfer_speed(transfer_id)

    for file_info in source_files:

        if transfer_id not in active_transfers:
            print(f"ä¼ è¾“ {transfer_id} å·²è¢«å–æ¶ˆ")
            return

        source_path = file_info['path']
        file_name = file_info['name']
        is_directory = file_info['is_directory']


        is_local_source = is_local_server(source_server)
        is_local_target = is_local_server(target_server)

        if is_local_source and not is_local_target:
            transfer_mode = 'local_to_remote'
        elif not is_local_source and is_local_target:
            transfer_mode = 'remote_to_local'
        elif is_local_source and is_local_target:
            transfer_mode = 'local_to_local'
        else:
            transfer_mode = 'remote_to_remote'

        simulated_speed = speed_simulator.get_simulated_speed(transfer_id)
        elapsed_time = time_tracker.get_elapsed_time(transfer_id)





        is_local_source = is_local_server(source_server)
        is_local_target = is_local_server(target_server)

        if transfer_mode == 'local_to_local':

            operation = "å‰ªåˆ‡" if mode == "move" else "å¤åˆ¶"
            cmd_name = "mv" if mode == "move" else "cp"
            print(f"ğŸ“ é¡ºåºä¼ è¾“-æœ¬åœ°åˆ°æœ¬åœ°{operation}: {source_path} -> {target_path}")
            emit_transfer_log(transfer_id, f'ğŸ”„ æœ¬åœ°åˆ°æœ¬åœ°ä¼ è¾“ï¼Œä½¿ç”¨{cmd_name}å‘½ä»¤')
            success = transfer_file_via_local_to_local_instant(source_path, target_path, file_name, is_directory, transfer_id, mode)
            if not success:
                raise Exception(f"æœ¬åœ°åˆ°æœ¬åœ°{operation}å¤±è´¥")
        elif is_local_source:

            success = transfer_file_via_local_rsync(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, completed_files, total_files, mode)
            if not success:
                raise Exception("æœ¬åœ°ä¼ è¾“å¤±è´¥")
        else:

            if source_server == target_server:

                is_windows = is_windows_server(source_server)
                if is_windows:
                    import ntpath
                    dest_path = ntpath.join(target_path, file_name)
                    src_cmd_path = normalize_windows_path_for_cmd(source_path)
                    dest_cmd_path = normalize_windows_path_for_cmd(dest_path)
                    if mode == "move":
                        emit_transfer_log(transfer_id, f'âœ‚ï¸ åŒæœåŠ¡å™¨å‰ªåˆ‡ï¼ˆWindowsï¼‰ï¼Œä½¿ç”¨move: {file_name}')
                        ps_src = src_cmd_path.replace("'", "''")
                        ps_dst = dest_cmd_path.replace("'", "''")
                        ps_script = (
                            "$ErrorActionPreference='Stop';"
                            f"$src='{ps_src}';$dst='{ps_dst}';"
                            "$same=[string]::Equals($src.TrimEnd('\\','/'),$dst.TrimEnd('\\','/'),"
                            "[System.StringComparison]::InvariantCultureIgnoreCase);"
                            "if($same){exit 0};"
                            "if(Test-Path -LiteralPath $dst){Remove-Item -LiteralPath $dst -Force -Recurse -ErrorAction SilentlyContinue};"
                            "Move-Item -LiteralPath $src -Destination $dst -Force -ErrorAction Stop"
                        )
                        remote_cmd = f'powershell -NoProfile -Command "{ps_script}"'
                    else:
                        emit_transfer_log(transfer_id, f'ğŸ“ åŒæœåŠ¡å™¨å¤åˆ¶ï¼ˆWindowsï¼‰ï¼Œä½¿ç”¨copy/xcopy: {file_name}')
                        if is_directory:

                            remote_cmd = f'xcopy "{src_cmd_path}" "{dest_cmd_path}" /E /I /Y /Q'
                        else:
                            remote_cmd = f'copy /Y "{src_cmd_path}" "{dest_cmd_path}"'
                else:
                    dest_path = os.path.join(target_path, file_name)
                    if mode == "move":
                        emit_transfer_log(transfer_id, f'âœ‚ï¸ åŒæœåŠ¡å™¨å‰ªåˆ‡ï¼ˆLinuxï¼‰ï¼Œä½¿ç”¨mv: {file_name}')
                        remote_cmd = f"mv -f {shlex.quote(source_path)} {shlex.quote(dest_path)}"
                    else:
                        emit_transfer_log(transfer_id, f'ğŸ“ åŒæœåŠ¡å™¨å¤åˆ¶ï¼ˆLinuxï¼‰ï¼Œä½¿ç”¨cp: {file_name}')
                        if is_directory:
                            remote_cmd = f"cp -r {shlex.quote(source_path)} {shlex.quote(dest_path)}"
                        else:
                            remote_cmd = f"cp -f {shlex.quote(source_path)} {shlex.quote(dest_path)}"

                stdout, stderr, exit_code = ssh_manager.execute_command(source_server, remote_cmd)
                if exit_code != 0:
                    err_msg = stderr or stdout or f"exit_code={exit_code}"
                    raise Exception(f"åŒæœåŠ¡å™¨{'å‰ªåˆ‡' if mode == 'move' else 'å¤åˆ¶'}å¤±è´¥: {err_msg}")

                emit_transfer_log(transfer_id, f'âœ… åŒæœåŠ¡å™¨{"å‰ªåˆ‡" if mode == "move" else "å¤åˆ¶"}å®Œæˆ: {file_name}')
            else:


                print(f"ğŸ”„ å¹¶è¡Œä¼ è¾“ä½¿ç”¨rsyncæ–¹æ¡ˆ")

                target_user = SERVERS[target_server]['user']
                target_password = SERVERS[target_server].get('password')
                source_user = SERVERS[source_server]['user']
                source_password = SERVERS[source_server].get('password')


                ssh_to_target = RSYNC_SSH_CMD


                target_port = SERVERS[target_server].get('port', 22)
                if target_port != 22:
                    ssh_to_target = f"{ssh_to_target} -p {target_port}"
                    print(f"ğŸ”§ ç›®æ ‡æœåŠ¡å™¨ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£: {target_port}")


                rsync_base_opts = [
                    "-a",
                    "--inplace",
                    "--whole-file",
                    "--no-compress",
                    "--numeric-ids",
                    "--timeout=600",
                    "-s",
                    "--no-perms",
                    "--no-owner",
                    "--no-group",
                    "--omit-dir-times",
                ]

                source_is_windows = is_windows_server(source_server)
                target_is_windows = is_windows_server(target_server)
                if source_is_windows or target_is_windows:
                    rsync_base_opts.append("--iconv=UTF-8,UTF-8")
                _append_rsync_progress_opts(rsync_base_opts)


                if source_is_windows and not target_is_windows:

                    sshpass_cmd = "sshpass"

                    ssh_to_source = RSYNC_SSH_CMD


                    source_port = SERVERS[source_server].get('port', 22)
                    if source_port != 22:
                        ssh_to_source = f"{ssh_to_source} -p {source_port}"
                        print(f"ğŸ”§ æºæœåŠ¡å™¨ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£: {source_port}")

                    rsync_source_path = convert_windows_path_to_cygwin(source_path)
                    if is_directory:
                        if source_password:
                            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(source_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}/')} {shlex.quote(f'{target_path}/{file_name}/')}"
                        else:
                            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}/')} {shlex.quote(f'{target_path}/{file_name}/')}"
                    else:
                        if source_password:
                            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(source_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}')} {shlex.quote(f'{target_path}/')}"
                        else:
                            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_source)} {shlex.quote(f'{source_user}@{source_server}:{rsync_source_path}')} {shlex.quote(f'{target_path}/')}"


                    ssh = ssh_manager.get_connection(target_server)
                    if not ssh:
                        raise Exception(f"æ— æ³•è¿æ¥åˆ°ç›®æ ‡æœåŠ¡å™¨ {target_server}")
                else:


                    sshpass_cmd = "sshpass"


                    rsync_target_path = convert_windows_path_to_cygwin(target_path) if target_is_windows else target_path
                    rsync_source_path = convert_windows_path_to_cygwin(source_path) if source_is_windows else source_path

                    if is_directory:
                        if target_password:
                            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(f'{rsync_source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/')}"
                        else:
                            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(f'{rsync_source_path}/')} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/{file_name}/')}"
                    else:
                        if target_password:
                            remote_cmd = f"{sshpass_cmd} -p {shlex.quote(target_password)} rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(rsync_source_path)} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/')}"
                        else:
                            remote_cmd = f"rsync {' '.join(rsync_base_opts)} -e {shlex.quote(ssh_to_target)} {shlex.quote(rsync_source_path)} {shlex.quote(f'{target_user}@{target_server}:{rsync_target_path}/')}"


                    ssh = ssh_manager.get_connection(source_server)
                    if not ssh:
                        raise Exception(f"æ— æ³•è¿æ¥åˆ°æºæœåŠ¡å™¨ {source_server}")

                import time
                start_time = time.time()

                emit_transfer_log(transfer_id, f'âš¡ï¸ å¼€å§‹ä¼ è¾“ {file_name}...')


                part_id = f"rsync_{uuid.uuid4().hex}"
                exit_status, error = _run_remote_rsync_with_progress(ssh, remote_cmd, transfer_id, part_id)
                if exit_status != 0:
                    raise Exception(f"ä¼ è¾“ {file_name} å¤±è´¥: {error}")


                end_time = time.time()
                duration = end_time - start_time

                emit_transfer_log(transfer_id, f'âœ… {file_name} ä¼ è¾“å®Œæˆ')

        completed_files += 1



        need_delete_source = mode == "move" and not (transfer_mode == 'local_to_local' or (transfer_mode == 'remote_to_remote' and source_server == target_server))

        if need_delete_source:
            try:
                if is_local_server(source_server):

                    import shutil
                    if is_directory:
                        shutil.rmtree(source_path)
                    else:
                        os.remove(source_path)
                    emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ å·²åˆ é™¤æºæ–‡ä»¶: {file_name}')
                else:

                    is_windows = is_windows_server(source_server)
                    if is_windows:

                        win_path = normalize_windows_path_for_cmd(source_path)


                        ps_path = win_path.replace('\\', '\\\\')
                        ps_check_cmd = f'powershell -Command "if (Test-Path -Path \'{ps_path}\' -PathType Container) {{ Write-Output \'DIR\' }} elseif (Test-Path -Path \'{ps_path}\' -PathType Leaf) {{ Write-Output \'FILE\' }} else {{ Write-Output \'NOTFOUND\' }}"'
                        ps_stdout, ps_stderr, ps_exit = ssh_manager.execute_command(source_server, ps_check_cmd)

                        is_dir = False
                        if ps_exit == 0 and ps_stdout:
                            result = ps_stdout.strip().upper()
                            if result == 'DIR':
                                is_dir = True
                            elif result == 'NOTFOUND':
                                emit_transfer_log(transfer_id, f'âš ï¸ æºæ–‡ä»¶ä¸å­˜åœ¨: {file_name}')
                                return


                        if is_dir:
                            delete_cmd = f'rd /s /q "{win_path}"'
                        else:
                            delete_cmd = f'del /f /q "{win_path}"'

                        emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ æ‰§è¡ŒWindowsåˆ é™¤å‘½ä»¤: {delete_cmd}')
                    else:

                        delete_cmd = f"rm -rf {shlex.quote(source_path)}"
                        emit_transfer_log(transfer_id, f'ğŸ—‘ï¸ æ‰§è¡ŒLinuxåˆ é™¤å‘½ä»¤: {delete_cmd}')

                    stdout, stderr, exit_code = ssh_manager.execute_command(source_server, delete_cmd)
                    if exit_code == 0:
                        emit_transfer_log(transfer_id, f'âœ… å·²åˆ é™¤æºæ–‡ä»¶: {file_name}')
                    else:
                        emit_transfer_log(transfer_id, f'âŒ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: {stderr}')
            except Exception as e:
                emit_transfer_log(transfer_id, f'âŒ åˆ é™¤æºæ–‡ä»¶å¼‚å¸¸: {str(e)}')

    # Stop transfer timing.
    total_time = time_tracker.end_transfer(transfer_id)

    _clear_transfer_listing_cache(source_server, target_server, source_files, target_path, mode)


    print(f"[æ€§èƒ½ç›‘æ§] ä¼ è¾“ID: {transfer_id}")
    print(f"[æ€§èƒ½ç›‘æ§] æ–‡ä»¶æ•°é‡: {len(source_files)}")
    print(f"[æ€§èƒ½ç›‘æ§] ä¼ è¾“æ—¶é—´: {total_time}")


    emit_transfer_bytes_snapshot(transfer_id)
    socketio.emit('transfer_complete', {
        'transfer_id': transfer_id,
        'status': 'success',
        'message': f'æˆåŠŸä¼ è¾“ {len(source_files)} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹',
        'total_time': total_time
    })


    try:
        meta = active_transfers.get(transfer_id, {})
        client_ip = meta.get('client_ip', 'æœªçŸ¥')
        target_base = meta.get('target_path', target_path)
        mode_meta = meta.get('mode', mode)
        files_meta = meta.get('source_files', source_files)
        if isinstance(files_meta, list):
            file_names = ','.join([f.get('name', '') for f in files_meta if isinstance(f, dict)])
            source_paths = ';'.join([f.get('path', '') for f in files_meta if isinstance(f, dict)])
        else:
            file_names = ''
            source_paths = ''

        append_transfer_log_record(
            source_ip=source_server,
            target_ip=target_server,
            source_path=source_paths or target_base,
            target_full_path=target_base,
            duration_sec=_hhmmss_to_seconds(total_time),
            status='success',
            error="",
            client_ip=client_ip,
            mode=mode_meta,
            file_name=file_names or (files_meta[0].get('name', '') if isinstance(files_meta, list) and files_meta else ''),
            action='transfer'
        )
    except Exception:
        pass

def format_file_size(bytes_str):
    """Convert bytes to human-readable size."""
    try:

        bytes_num = int(bytes_str.replace(',', ''))


        if bytes_num < 1024 * 1024:
            return f"{bytes_num / 1024:.1f} KB"
        elif bytes_num < 1024 * 1024 * 1024:
            return f"{bytes_num / (1024 * 1024):.1f} MB"
        elif bytes_num < 1024 * 1024 * 1024 * 1024:
            return f"{bytes_num / (1024 * 1024 * 1024):.2f} GB"
        else:
            return f"{bytes_num / (1024 * 1024 * 1024 * 1024):.2f} TB"
    except (ValueError, AttributeError):
        return bytes_str

def parse_rsync_progress(line):
    """Parse rsync progress output (--info=progress2)."""
    import re


    # "  1,234,567  89%   12.34MB/s    0:00:05"
    progress2_pattern = r'\s*(\d+(?:,\d+)*)\s+(\d+)%\s+([\d.]+\w+/s)\s+(\d+:\d+:\d+)'
    match = re.search(progress2_pattern, line)

    if match:
        bytes_transferred = match.group(1)
        percentage = int(match.group(2))
        speed = match.group(3)
        eta = match.group(4)

        return {
            'type': 'progress',
            'bytes_transferred': bytes_transferred,
            'bytes_transferred_formatted': format_file_size(bytes_transferred),
            'percentage': percentage,
            'speed': speed,
            'eta': eta,
            'message': f"è¿›åº¦: {percentage}% | é€Ÿåº¦: {speed} | å‰©ä½™: {eta}"
        }


    # "    32,768  26%  100.00kB/s    0:00:00      122,934 100%  400.00kB/s    0:00:00 (xfr#1, ir-chk=1000/2000)"
    detailed_pattern = r'(\d+,?\d*)\s+(\d+)%\s+([\d.]+\w+/s)\s+(\d+:\d+:\d+)\s+(\d+,?\d*)\s+(\d+)%\s+([\d.]+\w+/s)\s+(\d+:\d+:\d+)\s+\(xfr#(\d+),\s+ir-chk=(\d+)/(\d+)\)'
    match = re.search(detailed_pattern, line)

    if match:
        final_percent = int(match.group(6))
        final_speed = match.group(7)
        files_transferred = int(match.group(9))
        files_remaining = int(match.group(10))
        total_files = int(match.group(11))

        return {
            'type': 'progress',
            'percentage': final_percent,
            'speed': final_speed,
            'files_transferred': files_transferred,
            'files_remaining': files_remaining,
            'total_files': total_files,
            'message': f"è¿›åº¦: {final_percent}% | é€Ÿåº¦: {final_speed} | æ–‡ä»¶: {files_transferred}/{total_files}"
        }


    if "sent" in line and "received" in line and "bytes/sec" in line:
        return {
            'type': 'summary',
            'message': f"ä¼ è¾“å®Œæˆ: {line}"
        }

    return None


def _human_readable_size(num_bytes):
    try:
        num_bytes = float(num_bytes)
    except Exception:
        return f"{num_bytes} bytes"
    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
    idx = 0
    while num_bytes >= 1024 and idx < len(units) - 1:
        num_bytes /= 1024.0
        idx += 1
    return f"{num_bytes:.2f} {units[idx]}"

def _escape_pwsh_literal(path: str) -> str:

    return path.replace("'", "''")

def _human_timestamp():
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

def emit_run_output(run_id, message, is_error=False, final=False, exit_code=None, sid=None):
    """Push runtime output to the requesting client only."""
    try:
        data = {
            'run_id': run_id,
            'message': message,
            'is_error': is_error,
            'final': final,
            'exit_code': exit_code
        }
        target_room = sid
        if not target_room:
            with RUN_TASKS_LOCK:
                task = RUN_TASKS.get(run_id)
                if task:
                    target_room = task.get('sid') or task.get('room')
        if target_room:
            socketio.emit('run_output', data, room=target_room)
        else:
            socketio.emit('run_output', data)
    except Exception as e:
        print(f"âŒ å‘é€è¿è¡Œè¾“å‡ºå¤±è´¥: {e}")


def stream_local_command(command, run_id, file_path, is_windows, sid=None):
    """Stream local command execution with merged stdout/stderr."""
    emit_run_output(run_id, f"â–¶ï¸ å¼€å§‹è¿è¡Œ: {file_path}\n", is_error=False, final=False, sid=sid)
    work_dir = os.path.dirname(file_path) or None
    proc = None
    master_fd = None
    try:
        if not is_windows:
            master_fd, slave_fd = pty.openpty()
            proc = subprocess.Popen(
                command,
                shell=True,
                stdin=slave_fd,
                stdout=slave_fd,
                stderr=slave_fd,
                cwd=work_dir,
                preexec_fn=os.setsid,
                close_fds=True
            )
            os.close(slave_fd)
            with RUN_TASKS_LOCK:
                RUN_TASKS[run_id] = {'type': 'local', 'process': proc, 'fd': master_fd, 'sid': sid}

            while True:
                rlist, _, _ = select.select([master_fd], [], [], 0.1)
                if master_fd in rlist:
                    try:
                        data = os.read(master_fd, 1024)
                        if data:
                            try:
                                text = data.decode('utf-8', errors='replace')
                            except Exception:
                                text = str(data)
                            emit_run_output(run_id, text, is_error=False, final=False, sid=sid)
                        else:
                            break
                    except OSError:
                        break
                if proc.poll() is not None:

                    try:
                        while True:
                            data = os.read(master_fd, 1024)
                            if not data:
                                break
                            text = data.decode('utf-8', errors='replace')
                            emit_run_output(run_id, text, is_error=False, final=False, sid=sid)
                    except Exception:
                        pass
                    break

            exit_code = proc.returncode
            emit_run_output(run_id, f"\n[è¿è¡Œç»“æŸï¼Œé€€å‡ºç  {exit_code}]\n", is_error=exit_code != 0, final=True, exit_code=exit_code, sid=sid)
        else:
            proc = subprocess.Popen(
                command + " 2>&1",
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                cwd=work_dir,
                creationflags=subprocess.CREATE_NEW_PROCESS_GROUP
            )
            with RUN_TASKS_LOCK:
                RUN_TASKS[run_id] = {'type': 'local', 'process': proc, 'fd': None, 'sid': sid}

            if proc.stdout:
                for line in proc.stdout:
                    emit_run_output(run_id, line, is_error=False, final=False, sid=sid)
            proc.wait()
            exit_code = proc.returncode
            emit_run_output(run_id, f"\n[è¿è¡Œç»“æŸï¼Œé€€å‡ºç  {exit_code}]\n", is_error=exit_code != 0, final=True, exit_code=exit_code, sid=sid)
    except Exception as e:
        emit_run_output(run_id, f"è¿è¡Œå¼‚å¸¸: {e}\n", is_error=True, final=True, exit_code=-1, sid=sid)
    finally:
        with RUN_TASKS_LOCK:
            RUN_TASKS.pop(run_id, None)
        if master_fd is not None:
            try:
                os.close(master_fd)
            except Exception:
                pass


def stream_remote_command(server_ip, command, run_id, file_path, is_windows, sid=None):
    """Stream remote command execution with merged stdout/stderr."""
    emit_run_output(run_id, f"â–¶ï¸ å¼€å§‹è¿è¡Œ: {file_path}\n", is_error=False, final=False, sid=sid)
    ssh = ssh_manager.get_connection(server_ip)
    if not ssh:
        emit_run_output(run_id, f"æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ {server_ip}\n", is_error=True, final=True, exit_code=-1, sid=sid)
        return

    try:

        full_cmd = command + " 2>&1"
        stdin, stdout, stderr = ssh.exec_command(full_cmd, get_pty=True)
        with RUN_TASKS_LOCK:
            RUN_TASKS[run_id] = {'type': 'remote', 'channel': stdout.channel, 'server': server_ip, 'sid': sid}
        encoding = 'gbk' if is_windows else 'utf-8'


        while True:
            line_bytes = stdout.readline()
            if line_bytes:
                try:
                    line = line_bytes.decode(encoding, errors='replace')
                except Exception:
                    line = str(line_bytes)
                emit_run_output(run_id, line, is_error=False, final=False, sid=sid)
            else:
                if stdout.channel.exit_status_ready():
                    break
                time.sleep(0.05)

        exit_code = stdout.channel.recv_exit_status()
        emit_run_output(run_id, f"\n[è¿è¡Œç»“æŸï¼Œé€€å‡ºç  {exit_code}]\n", is_error=exit_code != 0, final=True, exit_code=exit_code, sid=sid)
    except Exception as e:
        emit_run_output(run_id, f"è¿è¡Œå¼‚å¸¸: {e}\n", is_error=True, final=True, exit_code=-1, sid=sid)
    finally:
        with RUN_TASKS_LOCK:
            RUN_TASKS.pop(run_id, None)


def stream_run_command(server_ip, command, file_path, run_id, is_windows, is_local, sid=None):
    """Background thread: stream command execution by server type."""
    if is_local:
        stream_local_command(command, run_id, file_path, is_windows, sid=sid)
    else:
        stream_remote_command(server_ip, command, run_id, file_path, is_windows, sid=sid)


def transfer_file_via_local_rsync(source_path, target_server, target_path, file_name, is_directory, transfer_id, fast_ssh, completed_files=0, total_files=1, mode='copy'):
    """High-speed local rsync transfer (same as original script)."""
    try:



        target_config = SERVERS[target_server]
        target_user = target_config['user']
        target_password = target_config.get('password')


        ssh_opts_str = RSYNC_SSH_CMD


        target_port = SERVERS[target_server].get('port', 22)
        if target_port != 22:
            ssh_opts_str = f"{ssh_opts_str} -p {target_port}"
            print(f"ğŸ”§ ç›®æ ‡æœåŠ¡å™¨ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£: {target_port}")


        final_target_path = target_path
        if is_windows_server(target_server):
            normalized = normalize_windows_path_for_transfer(target_path)
            final_target_path = convert_windows_path_to_cygwin(normalized)
            print(f"ğŸ”„ Windowsç›®æ ‡è·¯å¾„è½¬æ¢(æœ¬åœ°rsync): {target_path} -> {final_target_path}")


        if is_directory:

            source_with_slash = source_path.rstrip('/') + '/'
            target_full_path = f"{final_target_path}/{file_name}/"
        else:

            source_with_slash = source_path
            target_full_path = f"{final_target_path}/"


        rsync_opts = [
            '-a',
            '--inplace',
            '--whole-file',
            '--no-compress',
            '--numeric-ids',
            '--timeout=600',
            '-s',
            '--no-perms',
            '--no-owner',
            '--no-group',
            '--omit-dir-times',
        ]
        _append_rsync_progress_opts(rsync_opts)

        if target_password:

            cmd = ['sshpass', '-p', target_password, 'rsync'] + rsync_opts + [
                '-e', ssh_opts_str,
                source_with_slash,
                f"{target_user}@{target_server}:{target_full_path}"
            ]
        else:

            cmd = ['rsync'] + rsync_opts + [
                '-e', ssh_opts_str,
                source_with_slash,
                f"{target_user}@{target_server}:{target_full_path}"
            ]



        import time
        start_time = time.time()

        emit_transfer_log(transfer_id, f'âš¡ï¸ å¼€å§‹ä¼ è¾“ {file_name}...')

        part_id = f"rsync_{uuid.uuid4().hex}"
        return_code = _run_rsync_subprocess_with_progress(cmd, transfer_id, part_id)
        if return_code != 0:
            raise Exception(f"æœ¬åœ°rsyncä¼ è¾“å¤±è´¥ï¼Œé€€å‡ºç : {return_code}")


        end_time = time.time()
        duration = end_time - start_time


        if duration < 60:
            time_str = f"{duration:.1f}ç§’"
        elif duration < 3600:
            minutes = int(duration // 60)
            seconds = duration % 60
            time_str = f"{minutes}åˆ†{seconds:.1f}ç§’"
        else:
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            seconds = duration % 60
            time_str = f"{hours}å°æ—¶{minutes}åˆ†{seconds:.1f}ç§’"


        emit_transfer_log(transfer_id, f'âœ… {file_name} ä¼ è¾“å®Œæˆ')

        return True

    except Exception as e:
        raise Exception(f"æœ¬åœ°rsyncä¼ è¾“å¤±è´¥: {str(e)}")

def transfer_file_via_paramiko(source_path, target_server, target_path, file_name, is_directory, transfer_id):
    """Transfer files with Paramiko (local to remote)."""
    ssh = ssh_manager.get_connection(target_server)
    if not ssh:
        raise Exception(f"æ— æ³•è¿æ¥åˆ°ç›®æ ‡æœåŠ¡å™¨ {target_server}")

    sftp = ssh.open_sftp()

    try:
        if is_directory:

            remote_dir_path = f"{target_path}/{file_name}"
            emit_transfer_log(transfer_id, f'æ­£åœ¨ä¼ è¾“ç›®å½•: {file_name}')
            transfer_directory_to_remote(sftp, source_path, remote_dir_path, transfer_id)
        else:

            remote_file_path = f"{target_path}/{file_name}"
            emit_transfer_log(transfer_id, f'æ­£åœ¨ä¼ è¾“æ–‡ä»¶: {file_name}')
            sftp.put(source_path, remote_file_path)
    finally:
        sftp.close()



def transfer_directory_to_remote(sftp, local_dir, remote_dir, transfer_id):
    """Recursively transfer a directory to remote."""
    try:
        sftp.mkdir(remote_dir)
    except:
        pass

    for item in os.listdir(local_dir):
        local_path = os.path.join(local_dir, item)
        remote_path = f"{remote_dir}/{item}"

        if os.path.isfile(local_path):
            sftp.put(local_path, remote_path)
        elif os.path.isdir(local_path):
            transfer_directory_to_remote(sftp, local_path, remote_path, transfer_id)

def transfer_directory_from_remote(sftp, remote_dir, local_dir, transfer_id):
    """Recursively transfer a remote directory to local."""
    os.makedirs(local_dir, exist_ok=True)

    for item in sftp.listdir(remote_dir):
        remote_path = f"{remote_dir}/{item}"
        local_path = os.path.join(local_dir, item)

        try:
            stat = sftp.stat(remote_path)
            if stat.st_mode & 0o040000:
                transfer_directory_from_remote(sftp, remote_path, local_path, transfer_id)
            else:
                sftp.get(remote_path, local_path)
        except:
            pass


__all__ = [name for name in globals() if not name.startswith('__')]
